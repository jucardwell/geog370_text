[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GEOG370",
    "section": "",
    "text": "Preface\nThis textbook was developed by Julia Cardwell for GEOG370: Introduction to Geographic Information at UNC Chapel Hill.\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.\nLast Updated: July 2025",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 How did we get here?\nThis text is designed as a primer in introductory GIS concepts for GEOG370 (Introduction to Geographic Information) at the University of North Carolina. It is designed as part GIS textbook, part user manual for QGIS, and part introduction to critical GIS.\nHumans, as a species, have always had to orient ourselves to our environment and use our brains and bodies to move through and interpret space. We have always “thought spatially” about where things are, why they are there, and what it means that those things are there. Our spatial ability is a major part of our cognition, and the ability to navigate and remember places has allowed us to evolve as a species. As our societies became more complex, so did our need to externalize spatial knowledge. As a social species we have always needed ways to take what we know about space and communicate it to others. Externalizing spatial knowledge can come in many forms- words, gestures, songs, stories, physical markers, maps.\nWe experience space through our bodies: by moving through it, feeling it, and sensing it. This means that every person experiences space differently. At the same time, throughout history, there has also been a strong desire to own, control, and analyze space. Doing so has required a shared “spatial language”: a way to describe, divide, and represent space in consistent terms.\nOver time, a dominant, institutionalized way of externalizing and analyzing space emerged: Cartesian spatial logic. This is the idea that space can be abstracted into something measurable, gridded, uniform, and detached from lived experience. This logic, in general, has served those in power by enabling forms of standardization and control over space, which became important for statebuilding, population management, and surveillance. It is out of this logic that Geographic Information Systems (GIS) emerged. GIS is not a neutral tool, but has developed as an outgrowth of a certain way of knowing, organizing, analyzing, and externalizing space.\nOther ways of understanding and representing space have always existed. This text will ask students to critically interrogate the assumptions built into GIS and the Cartesian spatial logic that informs it. What kinds of spatial knowledge are emphasized, and what gets left out? How are data, analysis, and outputs shaped by political, social, and historical forces?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cloud, John. 2002. “American Cartographic Transformations During\nthe Cold War.” Cartography and Geographic Information\nScience 29 (3): 261–82. https://doi.org/10.1559/152304002782008422.\n\n\nCrampton, Jeremy, and Matthew W Wilson. 2015. “Harley and Friday\nHarbor: A Conversation with John Pickles.” Cartographica The\nInternational Journal for Geographic Information and\nGeovisualization 50 (1): 28–36. https://doi.org/10.3138/carto.50.1.06.\n\n\nD’Ignazio, Catherine, and Lauren F Klein. 2023. Data Feminism.\nLondon, England: MIT Press.\n\n\nDobson, Jerome E. 1983. “Automated Geography.” The\nProfessional Geographer: The Journal of the Association of American\nGeographers 35 (2): 135–43. https://doi.org/10.1111/j.0033-0124.1983.00135.x.\n\n\nElwood, Sarah, and Agnieszka Leszczynski. 2018. “Feminist Digital\nGeographies.” Gender, Place and Culture: A Journal of\nFeminist Geography 25 (5): 629–44. https://doi.org/10.1080/0966369x.2018.1465396.\n\n\nElwood, Sarah, and Matthew Wilson. 2017. “Critical\nGIS Pedagogies Beyond ‘Week 10:\nEthics’.” Geographical Information Systems 31\n(10): 2098–2116. https://doi.org/10.1080/13658816.2017.1334892.\n\n\nGoodchild, Michael F. 1992. “Geographical Information\nScience.” International Journal of Geographical Information\nSystems 6 (1): 31–45. https://doi.org/10.1080/02693799208901893.\n\n\nHaraway, Donna. 2013. “Rethinking Cyberfeminism(s): Race, Gender,\nand Embodiment.” In Women, Science, and Technology,\n387–403. Routledge. https://doi.org/10.4324/9780203427415-33.\n\n\nHarley, J B. 1989. “Deconstructing the Map.”\nCartographica The International Journal for Geographic Information\nand Geovisualization 26 (2): 1–20. https://doi.org/10.3138/e635-7827-1757-9t53.\n\n\nHoller, Joseph. 2020. “Teaching Critical Open\nGIS.” The Canadian Geographer. Geographe\nCanadien 64 (4): 484–94. https://doi.org/10.1111/cag.12521.\n\n\nLefebvre, Henri. 1991. The Production of Space. London,\nEngland: Blackwell.\n\n\nMartin, K, and J Wing. 2007. “The Discourse and Discipline of\nGIS.” Cartographica The International Journal\nfor Geographic Information and Geovisualization 42 (November):\n235–48. https://doi.org/10.3138/CARTO.42.3.235.\n\n\nMassey, Doreen B. 2005. For Space. Thousand Oaks, CA: SAGE\nPublications.\n\n\nNyerges, Timothy L. 1991. “Analytical Map Use.”\nCartography and Geographic Information Systems 18 (1): 11–22.\nhttps://doi.org/10.1559/152304091783805635.\n\n\nPickles, J. 1999. “Arguments, Debates, and Dialogues: The\nGIS-Social Theory Debate and the Concern for\nAlternatives.” Geographical Information Systems 1:\n49–60.\n\n\nPickles, John, ed. 1995. Ground Truth. Mappings. New York, NY:\nGuilford Publications.\n\n\nSheppard, Eric. 1995. “GIS and Society: Towards a\nResearch Agenda.” Cartography and Geographic Information\nSystems 22 (1): 5–16. https://doi.org/10.1559/152304095782540555.\n\n\nTaylor, Linnet. 2017. “What Is Data Justice? The Case for\nConnecting Digital Rights and Freedoms Globally.” Big Data\n& Society 4 (2): 205395171773633. https://doi.org/10.1177/2053951717736335.\n\n\nWood, D. 2003. “Cartography Is Dead (Thank God!).”\nCartographic Perspectives, January, 4–7. https://doi.org/10.14714/CP45.497.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "intro.html#asking-spatial-questions",
    "href": "intro.html#asking-spatial-questions",
    "title": "1  Introduction",
    "section": "1.2 Asking spatial questions",
    "text": "1.2 Asking spatial questions\nGIS is designed as one way to answer spatial questions. A spatial question is concerned about the role of space in influencing how our world works. For instance:\n\nAre there a disproportionate number of landfills in minority communities?\nWhich streams are most at risk from polluting facilities?\nWhere is the best place to locate new affordable housing in Carrboro? \nWho lives within 10 minutes of their nearest hospital? \nWhich parts of Chapel Hill have the most well-connected sidewalks? \nWhere are urban tree canopies most and least dense?\nWhich intersections have the highest number of pedestrian accidents?\nWhere are the highest-performing schools located, and who lives near them?\nWhat areas show high levels of commercial vacancy?\nHow has land use changed in downtown Durham since 1950?\nWhere are population densities increasing most rapidly within North Carolina?\n\nSpatial questions can ask about (from Nyerges (1991)):\n\nLocation\n\nWhere is it? \nWhy is it here or there? \nHow much of it is here or there? \n\nDistribution\n\nIs it distributed locally or globally?\nIs it spatially clustered or dispersed?\nWhere are the boundaries?\n\nAssociation\n\nWhat else is near it?\nWhat else occurs with it?\nWhat is absent in its presence?\n\nInteraction\n\nIs it linked to something else?\nWhat is the nature of this association?\nHow much interaction occurs between the locations?\n\nChange\n\nHas it always been here?\nHow has it changed over time and space?\nWhat causes its diffusion or contraction?\n\n\nNot every spatial question can be answered using a GIS. As we will learn throughout this course, a GIS is traditionally best suited for asking questions that allow for space to be represented in measurable, mappable terms. It can struggle to encode the emotional, relational, and lived aspects of space that shape our everyday experience.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#what-is-a-gis",
    "href": "intro.html#what-is-a-gis",
    "title": "1  Introduction",
    "section": "1.3 What is a GIS? ",
    "text": "1.3 What is a GIS? \nA Geographic Information System (GIS) is an integrated framework for exploring spatial questions. It is built around combining hardware, software, data, people, and methodologies to analyze space.\n\n\n\n\n\n\n\nComponent\nDescription\n\n\nHardware\nPhysical infrastructure used for GIS. This includes local computers, servers, data collection devices, etc.  \n\n\nSoftware\nApplications and platforms used to analyze, visualize, and manage geographic data. \n\n\nData\nData suitable for analysis in a GIS requires a locational component\n\n\nPeople\nUsers, developers, analysts, and decision-makers who interact with GIS.\n\n\nMethodologies\nTechniques that are implemented inside a GIS to process data and answer spatial questions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-layer-model",
    "href": "intro.html#the-layer-model",
    "title": "1  Introduction",
    "section": "1.4 The Layer Model",
    "text": "1.4 The Layer Model\nIn a GIS, spatial features are thought of as a set of layers. In the layer model, the world can be represented by translating real-world phenomena into a model composed of separate, stackable layers. For instance, a layer model representing the ecology of North Carolina might have a layer representing rivers, one representing forests, and one representing species ranges. \n\n\n\nThe Layer Model (from Essentials of Geographic Information Fig 1.8, CC BY-NC-SA 3.0)\n\n\nThe layer approach necessarily relies on abstraction: the process of simplifying complex real-world features into layer representations that GIS software can manage and analyze. Trying to represent every feature with complete accuracy is impossible from a data storage, collection, and analysis perspective\nAbstraction always involves decisions, and those decisions will impact the outcome of any GIS analysis using the data. Abstraction is guided by the original purpose of the dataset. The purpose allows data creators to determine what aspects of the real-life feature are important (and therefore should be collected and represented with high accuracy) and which aspects are less important (and can be generalized or omitted). A mismatch between your purpose for using the data and the abstraction decisions made in the data creation process can be a serious issue for the reliability of your results. \nConsider the following example of different uses for the same dataset- hospitals in North Carolina:\n\nAn engineer assessing flood risk at hospitals in North Carolina\nA public health analyst investigating disease outbreaks across hospitals in North Carolina\n\nWhat is considered important to these two users differ greatly. The engineer may require detailed building footprints to evaluate structural exposure. The public health analyst may want detailed information on the number of beds and the infectious disease protocols, but just need a rough location for the hospital. If these users were creating the datasets themselves, they would likely look very different. However, most of the time, users aren’t collecting or creating the data themselves, they’re working with data that already exists. As a result, it’s crucial for users to critically evaluate the dataset’s underlying abstraction decisions regarding: \n\nSelection - What features are included or excluded?\nClassification - How are features grouped?\nSimplification - How much detail of the original feature is retained?\nResolution- What is the smallest feature the data can meaningfully represent? \n\nFurthermore, all spatial data comes with some degree of uncertainty and error\n\nErrors include positional inaccuracies, attribute inaccuracies, or conceptual inaccuracies\nUncertainty refers more broadly to the limits of our knowledge about the data. This might include incomplete data, ambiguous classifications, unknown data sources, or the inability to verify how a measurement was taken. \n\nWhat ultimately matters is not whether the data is perfect, but whether the level and type of abstraction, error, and uncertainty are acceptable enough for the analysis you are doing.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#limits-of-the-layer-model",
    "href": "intro.html#limits-of-the-layer-model",
    "title": "1  Introduction",
    "section": "1.5 Limits of the Layer Model",
    "text": "1.5 Limits of the Layer Model\nThe layer model depends on a Cartesian spatial logic, which is a framework that treats space as something that can be quantified, segmented, and rationalized. In Cartesian logic, space is imagined as fixed (every location has a precise, mappable set of coordinates), abstract (detached from the meanings people assign to it), homogeneous (space is uniform), and measurable (can be divided into distances, areas, and directions). This standardized view of space underlies many of the spatial practices GIS draws from- spatial analysis, cartography, land surveying, remote sensing, and military mapping.\nBut this model has limits. The idea that space can be broken into layers, each objectively representing a part of the world, leaves out other ways people understand and interact with their environments. Spatial logic is not universal. Different cultures and communities experience space in ways that are relational, embodied, and emotional. What matters in a landscape may not be what’s easily mapped, and what’s included in a GIS layer may not reflect how people actually move through or value a place.\nTo that end, there are many alternative conceptualizations of space. For instance:\nDoreen Massey (Massey (2005))\n\nSpace is relational\n\nFormed through interactions, from the global scale to everyday encounters.\n\nSpace is the sphere of possibility\n\nMultiple trajectories coexist; space exists because of multiplicity and difference.\n\nSpace is always under construction\n\nIt’s a process- never fixed or finished, made up of “simultaneities of stories-so-far.”\n\n\nHenri Lefebvre (Lefebvre (1991))\nSpace is made up of:\n\nSpatial Practice (Perceived Space)\n\nPhysical and material space as experienced in daily life (e.g., walking through a city).\n\nRepresentations of Space (Conceived Space):\n\nAbstract, planned space created by experts (e.g., maps, zoning, blueprints)\n\nSpaces of Representation (Lived Space):\n\nEmotional, symbolic, and cultural space as lived and felt by people.\n\nSocieties privilege conceived space, which fragments and commodifies the world. This abstract space suppresses difference and bodily experience. Through reclaiming space (imagining and enacting alternatives) we can move toward differential space: a space that embraces multiplicity, creativity, and the right to difference.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#what-is-critical-gis",
    "href": "intro.html#what-is-critical-gis",
    "title": "1  Introduction",
    "section": "1.6 What is Critical GIS? ",
    "text": "1.6 What is Critical GIS? \nCritical GIS recognizes that GIS is not a neutral tool, it is a power-laden practice. As a subfield or alternative knowledge structure, critical GIS has been employed as a critical analysis of GIS, and as a critical analysis through GIS. A critical analysis of GIS examines the origins, development, and institutional uses of GIS technology, highlighting how it has been shaped by and contributed to systems of power, including those of the state, military, and private industry. This strand interrogates the assumptions embedded in spatial data, software design, and dominant spatial logics. A critical analysis through GIS uses the existing tools and methods of GIS to advance social justice, expose spatial inequalities, and support marginalized communities. This includes work such as mapping environmental racism, visualizing housing insecurity, or enabling participatory planning processes that center community knowledge. Critical analysis through GIS also includes the development of alternative spatial methods, such as feminist GIS, counter-mapping, and qualitative GIS. \nRead: O’Sullivan, David. “Geographical information science: critical GIS.” Progress in human geography 30, no. 6 (2006): 783-791.\n\n\n\n\nLefebvre, Henri. 1991. The Production of Space. London, England: Blackwell.\n\n\nMassey, Doreen B. 2005. For Space. Thousand Oaks, CA: SAGE Publications.\n\n\nNyerges, Timothy L. 1991. “Analytical Map Use.” Cartography and Geographic Information Systems 18 (1): 11–22. https://doi.org/10.1559/152304091783805635.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "politics.html",
    "href": "politics.html",
    "title": "2  Politics and Potentials of GIS",
    "section": "",
    "text": "2.1 Historical Foundations\nThis chapter introduces GIS not as a neutral technical tool, but as a sociotechnical system. As a sociotechnical system, the assumptions and applications of GIS are embedded in its historic and present development. By tracing GIS’s origins in government planning, the rise of commercial dominance (especially Esri), and the emergence of critical GIS, this chapter reveals the contradictions and tensions that persist within the GIS technosphere. Understanding this context prepares us to learn and think critically through, against, and beyond GIS.\nAs introduced in Chapter 1, humans have always thought about, analyzed, and represented space. Even in ancient times, people developed systems to record and interpret spatial information and these systems were almost always closely tied to state-building and governances.As early as 1900 BCE, the Babylonians were using advanced applied geometric methods to divide valuable farmland, documenting these divisions on some of the earliest known cadastral maps.\nGIS, specifically, is concerned about spatial analysis- extracting additional insight from spatial features. There are many examples of pre-digital spatial analysis, for instance, John Snow’s 1854 cholera map, which plotted cholera deaths across London and revealed a cluster near a contaminated water pump, ultimately helping to identify the source of the outbreak. However, the widely recognized birthplace of modern GIS is our northern neighbor. Roger Tomlinson, an employee of the Canadian government, created the first computerized geographic information system. This system, named the Canada Geographic Information System, was designed to store geospatial data for the Canada Land Inventory, allowing analysts to inventory and overlay different datasets (layers) of natural resources in Canada. While the actual mechanics differed significantly from modern GIS, the underlying logic of layering and analyzing spatial data remains central today.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#historical-foundations",
    "href": "politics.html#historical-foundations",
    "title": "2  Politics and Potentials of GIS",
    "section": "",
    "text": "Babylonian Tablet, Credit: Daniel.mansfield, CC BY-SA 4.0, via Wikimedia Commons",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#corporate-dominance",
    "href": "politics.html#corporate-dominance",
    "title": "2  Politics and Potentials of GIS",
    "section": "2.2 Corporate Dominance",
    "text": "2.2 Corporate Dominance\nWhile the Canada Geographic Information System was developed for a specific government use case, it quickly became clear that the logic of GIS could be applied across virtually every public and private sector. As various government institutions and private industries began to see the potentials of GIS, it quickly became a valuable (and marketable) product. In the United States, one of the early hubs for GIS development, particularly broad-use GIS development, was the Harvard Laboratory for Computer Graphics and Spatial Analysis, which was founded in 1965. This lab developed some of the first general-purpose GIS software tools. While the lab’s priorities were research/academic focused, these academic developments quickly lead to growing commercial interest.\nOne of the lab assistants in the Harvard lab, Jack Dangermond, went on to found the Environmental Systems Research Institute (Esri), which originally focused on land use planning consulting. Over time, Esri pivoted towards software development and released a series of increasingly dominant GIS tools that created a flexible GIS framework that could be applied across urban planning, resource management, transportation, environmental monitoring, defense, etc. \nEsri’s business success is due to a couple main reasons: \n\nEsri developed tools with a graphical user interface (GUI), which means that GIS became much more accessible to non-programmers through point-and-click functionality (as opposed to the command line). \nThey introduced file formats like the shapefile and geodatabase, which became de facto standards across the GIS industry\nVendor lock-in. As organizations invested in Esri’s ecosystem, switching to other systems became prohibitively expensive and time-consuming. When the U.S. federal government became an early adopter, this lock-in cascaded down to state and local governments, contractors, and educational institutions.\nBecause of this vendor lock-in, Esri developed what Joe Morrison terms “pedagogical capture”. Because Esri became the industry standard, universities trained students in Esri software; and because students entered the workforce already trained in Esri, employers demanded continued use of Esri products. \n\nBy the early 2000s Esri products were essentially synonymous with GIS software (think Kleenex). Despite the existence of alternatives, GIS education and practice became deeply embedded in Esri’s proprietary ecosystem, shaping how people learned to think about and use geographic technologies. Today, Esri maintains a dominant market share across sectors, even as open-source and code based (especially R and Python) alternatives emerge. While these alternatives challenge Esri’s monopoly in important ways, Esri remains a powerful force in shaping not just the tools we use, but the assumptions, practices, and institutions that define GIS. Alongside the rise of corporate GIS has been the rise of what I think of as the “inevitability” of GIS.  The idea that of course this is how we manage and analyze space and spatial data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#the-emergence-of-critical-gis",
    "href": "politics.html#the-emergence-of-critical-gis",
    "title": "2  Politics and Potentials of GIS",
    "section": "2.3 The Emergence of Critical GIS",
    "text": "2.3 The Emergence of Critical GIS\nAs the utilization of GIS increased in the late 20th century, some academic researchers began to argue that it was more than just a technology, it was the foundation for a new scientific field. Scholars like Dobson (1983) and Goodchild (1992). were the leaders in defining Geographic Information Science (GIScience) as the study of how geographic data is created, analyzed, and understood. They saw GIS as a way to make the field of geography more rigorous, predictive, and unified through shared computational methods. GIScience focused on formalizing geographic techniques for modeling, storing data, and executing spatial analysis and focused especially on how these approaches can be integrated into a GIS system. The GIScience field also aimed to address core challenges in analyzing spatial data, like how to represent space and time, how to deal with uncertainty and error, how scale affects analysis, and how spatial thinking could be formalized in algorithms.\nAt the same time, other scholars began to explore and critique the epistemological assumptions embedded in GIS. Epistemology is the branch of philosophy concerned with knowledge. It asks questions like:\n\nWhat counts as knowledge? \nHow do we know what we know?\nWhat are the limits of knowledge?\nWhat makes something true?\n\nThe assumptions in a GIS are rooted in positivism, which is the idea that knowledge comes from direct observation and measurement, and that scientific methods can lead us to discovering objective truths about the world. In a positivist view, GIS is seen as a neutral, technical tool for producing accurate representations of spatial reality (which is exactly what the GISciencers were arguing). This view of GIS considers that:\n\nThe world is made up of discrete, observable spatial objects\nSpace is absolute, continuous, and measurable\nKnowledge is produced through empirical data and computational logic\nMapping and visualization produce objective truths\nProblems can be solved through technical optimization\nData is neutral and meaning arises from analysis, not context\nThe GIS user is a rational decision-maker\n\nScholars such as Sheppard (1995) began to argue that GIS is not a neutral system, it is a social technology. This means that GIS is shaped by the social, political, and institutional context in which it was developed (Cloud (2002)).\nJohn John Pickles (1995), a recently retired processor in our department, critiqued GIS for reinforcing a positivist, technocratic view of space at a time when human geography was moving away from an emphasis on formal spatial models and towards a more critical, interpretive, and qualitative approach for analyzing space. This thread of academic work developed “strong critiques of the reductionist ontology of spatialism” J. Pickles (1999) in which space can be fully understood through a neutral lens. Instead, he argues that space is socially and politically constructed. Space gets its meaning from how people live in it.\nThe increasing gulf between the enthusiasts and the critics of GIS culminated in a meeting at Friday Harbor in Washington State in 1993. The Friday Harbor meetings are widely recognized as the beginning of the formalization of critical GIS, which became known as the GIS and Society research agenda. Rather than deepening the rift between critical geographers and GISciencers, the Friday Harbor conversations were focused on “finding a way to talk across” epistemological divides and explore what GIS might become (Crampton and Wilson (2015)). This meeting encouraged a shift “from critique to involvement,” inviting geographers to ask not just whether GIS was compatible with critical theory, but how it could be used critically (Crampton and Wilson (2015)).\nIn the years that followed, a range of GIS approaches emerged that use GIS technology in critical ways. Feminist GIS challenges masculinist assumptions of space and emphasizes embodiment, care, and situated knowledge. Participatory GIS focuses on community-led mapping and empowerment, often in contexts of marginalization. Qualitative GIS explored how narratives, interviews, and emotions could be visualized and spatialized. Other approaches, like Indigenous and decolonial GIS, emphasized sovereignty, place-based knowledge, and resistance to colonial mapping systems.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#feminist-gis",
    "href": "politics.html#feminist-gis",
    "title": "2  Politics and Potentials of GIS",
    "section": "2.4 Feminist GIS",
    "text": "2.4 Feminist GIS\nKwan, Mei-Po. (2002). “Feminist Visualization: Re-envisioning GIS as a Method in Feminist Geographic Research.” Annals of the AAG, 92(4), 645–661.\nSchuurman, Nadine & Pratt, Geraldine. (2002). “Care of the Subject: Feminism and Critiques of GIS.” Gender, Place & Culture, 9(3), 291–299.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#participatory-gis",
    "href": "politics.html#participatory-gis",
    "title": "2  Politics and Potentials of GIS",
    "section": "2.5 Participatory GIS ",
    "text": "2.5 Participatory GIS \nHarris, Trevor & Weiner, Daniel. (1998). “Empowerment, Marginalization and ‘Community-integrated GIS.’” Cartography and Geographic Information Systems, 25(2), 67–76.\nElwood, Sarah. (2006). “Negotiating Knowledge Production: The Everyday Inclusions, Exclusions, and Contradictions of Participatory GIS.” The Professional Geographer, 58(2), 197–208.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#qualitative-gis",
    "href": "politics.html#qualitative-gis",
    "title": "2  Politics and Potentials of GIS",
    "section": "2.6 Qualitative GIS",
    "text": "2.6 Qualitative GIS\nCope, Meghan & Elwood, Sarah. (2009). “Qualitative GIS: A Mixed Methods Approach.” In Qualitative GIS: A Mixed Methods Approach, eds. Cope & Elwood. SAGE Publications.\nPavlovskaya, Marianna. (2006). “Theorizing with GIS: A Tool for Critical Geographies?”\nEnvironment and Planning A, 38(11), 2003–2020.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#indigenous-and-decolonial-gis",
    "href": "politics.html#indigenous-and-decolonial-gis",
    "title": "2  Politics and Potentials of GIS",
    "section": "2.7 Indigenous and Decolonial GIS",
    "text": "2.7 Indigenous and Decolonial GIS\nLouis, Renee Pualani. (2007). “Can You Hear Us Now? Voices from the Margin: Using Indigenous Methodologies in GIS.” Geographical Research, 45(2), 130–139.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#affective-and-critical-data-studies",
    "href": "politics.html#affective-and-critical-data-studies",
    "title": "2  Politics and Potentials of GIS",
    "section": "2.8 Affective and Critical Data Studies",
    "text": "2.8 Affective and Critical Data Studies\nLeszczynski, Agnieszka. (2009). “Quantitative Limits to Qualitative Engagements: GIS, Its Critics, and the Philosophical Divide.” The Professional Geographer, 61(3), 350–365.\nWilson, Matt & Graham, Mark. (2013). “Situating Neogeography.” In Critical GIS: Theory and Practice, edited by Schuurman & Wilson, 1–21. Wiley-Blackwell.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "politics.html#goals-of-this-class",
    "href": "politics.html#goals-of-this-class",
    "title": "2  Politics and Potentials of GIS",
    "section": "2.9 Goals of this Class",
    "text": "2.9 Goals of this Class\nMy goal is to teach GIS critically in this course. This requires navigating tensions between GIS as a powerful set of tools for analyzing spatial patterns (that is used ubiquitously across public and private sectors) and GIS as a set of tools with a history of entrenching institutional power, epistemological assumptions, and a particular way of seeing the world. These tensions are especially powerful in pedagogical approaches (the method and practice of teaching).\nGIS pedagogy often falls into a problematic binary: critical GIS courses that emphasize reading and discussion about GIS without doing GIS, and technical classes that do GIS without meaningfully engaging in the critiques. This course aims to disrupt that binary. Instead of treating critique and practice as opposites, we will treat them as co-constitutive. As Elwood and Wilson (2017) writes, critical GIS is not just a body of literature, it is a way of doing GIS and as Martin and Wing (2007) argue, instruction can be a site for transformation of GIS. In this course, students will be introduced to the core GIS techniques needed to develop a foundational GIS skillset, while simultaneously interrogating the assumptions embedded in those processes.\nFurther, in this course, we will practice Open GIS. As discussed earlier in the chapter, the vast majority of GIS courses use proprietary software, engaging with the commercial GIS ecosystem. Free and Open Source alternatives do exist. Open GIS disrupts the representation of GIS as a single inevitable technology. Open GIS is not only a collection of alternative software projects, it is an alternative mode of engaging with GIS, recognizing that GIS software itself is a social artifact. Teaching critical open GIS allows students to become “conflicted insiders”- able to participate in the practice of GIS while meaningfully engaging with the values, assumptions, and power structures embedded in its design and use (Holler (2020)).\n\n\n\n\nCloud, John. 2002. “American Cartographic Transformations During the Cold War.” Cartography and Geographic Information Science 29 (3): 261–82. https://doi.org/10.1559/152304002782008422.\n\n\nCrampton, Jeremy, and Matthew W Wilson. 2015. “Harley and Friday Harbor: A Conversation with John Pickles.” Cartographica The International Journal for Geographic Information and Geovisualization 50 (1): 28–36. https://doi.org/10.3138/carto.50.1.06.\n\n\nDobson, Jerome E. 1983. “Automated Geography.” The Professional Geographer: The Journal of the Association of American Geographers 35 (2): 135–43. https://doi.org/10.1111/j.0033-0124.1983.00135.x.\n\n\nElwood, Sarah, and Matthew Wilson. 2017. “Critical GIS Pedagogies Beyond ‘Week 10: Ethics’.” Geographical Information Systems 31 (10): 2098–2116. https://doi.org/10.1080/13658816.2017.1334892.\n\n\nGoodchild, Michael F. 1992. “Geographical Information Science.” International Journal of Geographical Information Systems 6 (1): 31–45. https://doi.org/10.1080/02693799208901893.\n\n\nHoller, Joseph. 2020. “Teaching Critical Open GIS.” The Canadian Geographer. Geographe Canadien 64 (4): 484–94. https://doi.org/10.1111/cag.12521.\n\n\nMartin, K, and J Wing. 2007. “The Discourse and Discipline of GIS.” Cartographica The International Journal for Geographic Information and Geovisualization 42 (November): 235–48. https://doi.org/10.3138/CARTO.42.3.235.\n\n\nPickles, J. 1999. “Arguments, Debates, and Dialogues: The GIS-Social Theory Debate and the Concern for Alternatives.” Geographical Information Systems 1: 49–60.\n\n\nPickles, John, ed. 1995. Ground Truth. Mappings. New York, NY: Guilford Publications.\n\n\nSheppard, Eric. 1995. “GIS and Society: Towards a Research Agenda.” Cartography and Geographic Information Systems 22 (1): 5–16. https://doi.org/10.1559/152304095782540555.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Politics and Potentials of GIS</span>"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "3  Core Spatial Concepts",
    "section": "",
    "text": "3.1 Tobler’s First Law of Geography\nThe following core spatial concepts are considered assumptions in most spatial analysis methods. Practicing critical GIS means we should examine these assumptions. When are they not true? How do they shape the output of our analysis? For each of the following concepts, consider when they might not hold up- when space doesn’t behave the way our models expect, and when people’s experiences of space diverge from what GIS can represent. Understanding these moments of mismatch helps us become more thoughtful and responsible spatial analysts.\nThis “law”, coined by geographer Waldo Tobler in 1970, states that “everything is related to everything else, but near things are more related than distant things.” This principle captures a foundational idea in spatial analysis: spatial relationships tend to weaken with distance. As a result, places that are closer together tend to have stronger influence on one another than those farther apart. This assumption underlies most geographic models and spatial analysis methods. For example, consider the spread of an infectious disease like the flu. When the flu begins spreading in a city, nearby neighborhoods would tend to see more outbreaks than distant areas. This pattern occurs because people are more likely to come into contact with others in close proximity.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#where-does-geographic-data-come-from-and-how-is-it-collected",
    "href": "core.html#where-does-geographic-data-come-from-and-how-is-it-collected",
    "title": "3  What is Geographic Data?",
    "section": "3.2 Where does geographic data come from and how is it collected ",
    "text": "3.2 Where does geographic data come from and how is it collected \nHistorically, geospatial data was collected almost exclusively by state institutions, militaries, and professional surveyors. These data sources were considered “authoritative” because they relied on credentialed experts, standardized tools, and formal methodologies to achieve a high degree of accuracy. Early data collection involved resource-intensive methods like land surveying (using total stations and reference points), aerial photography for photogrammetry, remote sensing, and field data collection during censuses. The tools were expensive, slow, and required specialized training, but they produced high-quality data with thorough documentation (metadata). At the same time, they necessarily represented and re-created the priorities of those funding its acquisition. \nSome of the common sources of “authoritative” spatial data include: \n\nUS Census Bureau\n\nPopulation counts and demographics (e.g., race, age, income)\nHousing and economic data\nGeographic boundaries (e.g., census tracts, block groups, ZIP code tabulation areas)\n\nUS Geological Survey (USGS) \n\nTopographic maps\nElevation and terrain (e.g., DEMs)\nLand cover and land use (e.g., NLCD)\nHydrography (rivers, lakes, watersheds)\nGeologic and seismic data\n\nNASA\n\nWeather and climate data\nCoastal and marine mapping (e.g., nautical charts, sea surface temperature)\nFlood zones and storm surge models\nFisheries and oceanographic data\n\nState and Local Governments\n\nParcel and zoning data\nTransportation networks (roads, transit routes)\nUtilities and infrastructure (e.g., water lines, sewer systems)\nLand use plans and municipal boundaries\n\nEPA\n\nAir and water quality data\nEnvironmental justice mapping (e.g., EJScreen)\nRegulated facility locations",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "core.html#collection-methods",
    "href": "core.html#collection-methods",
    "title": "3  What is Geographic Data?",
    "section": "3.3 Collection methods",
    "text": "3.3 Collection methods\n\n3.3.1 Remote sensing\nUses satellites or aircraft to capture reflected or emitted energy from the Earth’s surface. Because different surfaces reflect energy at different wavelengths, this method can be used to identify and classify surfaces on earth.\n\n\n\nRemote Sensing, Credit: Arkarjun, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\n\n3.3.2 Land Surveys\nSurveying is a method of collecting highly accurate location data by measuring distances and angles between known points on the ground. Surveyors often use tools like total stations, which send laser signals to a reflective prism to calculate distance and direction, or survey-grade GPS units that use satellite signals with corrections from nearby base stations to achieve centimeter-level accuracy. By combining these measurements with known reference points (control points), surveyors can calculate the precise coordinates of new locations. \n\n\n\nLand Survey Equipment, Credit: Bureau of Land Management Oregon and Washington, Public domain, via Wikimedia Commons\n\n\n\n\n3.3.3 Sensors\nSensors are placed in fixed locations and are typically used to collect environmental data, such as air pollution, rainfall, or noise levels, over short or extended periods of time. For instance, the national ASOS/AWOS network consists of over 900 stations across the US collecting weather data for over 30 years. \n\n\n\nAWOS Station, Credit: Famartin, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\n\n3.3.4 GPS/GNSS\nGPS works through trilateration, which determines location by measuring distances from multiple satellites. Each satellite sends a signal with the time it was sent which allows GPS devices on the ground to calculate how far the satellite is from the device location. With signals from at least four satellites, the GPS receiver can determine your exact position on Earth (latitude, longitude, and elevation). GPS uses only the US satellite network, GNSS uses the global network.\n\n\n\nTrilateration, Credit: Javiersanp, CC BY-SA 4.0, via Wikimedia Commons\n\n\n\n\n3.3.5 Aerial Photography\nImages captured from planes or drones are used to document the Earth’s surface\n\n\n\nImagery Collected after Hurricane Helene, Credit: NOAA\n\n\n\n\n3.3.6 LiDAR (Light Detection and Ranging)\nLiDAR uses rapid laser pulses from aircraft or drones to measure the distance to the ground. By calculating how long it takes the light to bounce back, LiDAR can produce highly detailed 3D models. \n\n\n3.3.7 Photogrammetry\nPhotogrammetry involves taking many overlapping images of the same area, usually from drones or aircraft, and using software to extract depth, shape, and spatial relationships. It’s commonly used for creating orthophotos, elevation models, and 3D reconstructions.\n\n\n\nPhotogrammetry, Credit: NELAC , CC BY-SA 4.0, via Wikimedia Commons\n\n\n\n\n3.3.8 Census and Surveys\nThese methods gather demographic, social, and economic data directly from people through questionnaires, interviews, or field observations. The U.S. Census, for example, collects data on population, housing, and income and ties this information to geographic areas for mapping and policy use.\n\n\n3.3.9 Could Be Spatial Data\nMany data sources contain locational information, even if geography is not their primary focus. For example, health records often include patient zip codes, census tracts, or home addresses; tax documents may list property locations or mailing addresses; school enrollment data might be tied to district boundaries or bus routes. While these datasets are not explicitly spatial in origin, they become spatial when analyzed through the lens of geography.\n\n\n3.3.10 New Sources of Geographic Data\nCollecting geospatial data is now easier than ever. Almost every smartphone has built-in GPS/GNSS. Instead of the ability to collect geospatial data being relatively restricted, it is now possible for nearly anyone to record geographic data. In addition, the rise of online mapping tools like Google Earth has also made geospatial technologies more accessible to the public. As a result, geospatial data collection is no longer confined to experts or specialized equipment, leading to an explosion in the amount of data being generated. These crowdsourced and citizen-generated datasets are now used to support everything from disaster response to urban planning.\nSome well-known examples include:\n\nOpenStreetMap: A free, crowdsourced map of the world built by millions of contributors, widely used in humanitarian efforts and mapping underserved areas.\nMapillary: A platform where users upload street-level imagery to support navigation, urban development, and computer vision training.\neBird: A citizen science project where birdwatchers record sightings, contributing to biodiversity monitoring and conservation.\niNaturalist: A platform where people document observations of plants and animals, helping scientists track species distribution and ecological change.\n\nCrowdsourced or community-collected geospatial data has become an increasingly important way to capture information that is intentionally or unintentionally missed by “authoritative” sources. These grassroots efforts often seek to fill data gaps that disproportionately affect marginalized communities. However, the rise of crowdsourced data has also created tension between official and unofficial sources, which has raised questions about what kinds of data are considered legitimate and who is qualified to collect them. \n\n\n3.3.11 Case Study\nLouisiana Bans Community Air Quality Data\nIn Louisiana, particularly in the heavily industrialized region known as “Cancer Alley”, residents have been raising concerns about high levels of pollution near industrial facilities. A lack of “authoritative” air pollution data in the area (due to the EPA’s sparse and unevenly distributed monitoring network) meant that community members were unable to validate their concerns. In response, community members began using low-cost air quality sensors to collect their own data. \nHowever, in May 2023, Louisiana passed legislation banning the use of community-collected air quality data in legal or regulatory processes. Lawmakers justified the ban by citing concerns about the accuracy, calibration, and scientific rigor of the sensors used. This decision effectively invalidated grassroots efforts to document environmental health risks and reinforced institutional control over which data “counts.” It also revealed deeper tensions around participatory data, raising questions about who defines data quality, how metadata and standards are used to include or exclude information.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "core.html#metadata",
    "href": "core.html#metadata",
    "title": "3  What is Geographic Data?",
    "section": "3.4 Metadata",
    "text": "3.4 Metadata\nMetadata adds context to a geographic dataset by providing information on how, why, when, and by whom geographic data were collected. Understanding this context is essential for determining whether a dataset can/should be used in a certain analysis. In particular, metadata should answer the following questions:\n\nWhat is this data about?\nWhere did it come from?\nWhen was it gathered?\nHow is it organized?\nHow is it located on earth? \nWhat features does this data describe and in how much detail?\nWhat kind of features does this data set describe and in how much detail?\nWho documented the data? \n\nGeospatial metadata is often stored using standardized formats that are structured in XML. There are different metadata standards- such as FGDC (Federal Geographic Data Committee) or ISO 19115- which define consistent ways to create metadata. Metadata is typically embedded within the data file itself (like in a GeoTIFF), stored alongside it as an auxiliary XML file, or managed in a separate metadata catalog or database.\nAt the same time, metadata often acts as a kind of “gatekeeper” to authoritative spatial data sources, acting as a determining factor to what data is considered trustworthy, usable, or legitimate. A lack of standardized metadata is frequently used as a reason to dismiss crowdsourced or community-collected data, regardless of its relevance or local accuracy. In this way, metadata standards can reinforce institutional control over which data counts and whose knowledge is valued.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "core.html#open-data",
    "href": "core.html#open-data",
    "title": "3  What is Geographic Data?",
    "section": "3.5 Open Data",
    "text": "3.5 Open Data\nUntil recently, most geospatial data was difficult for the public to access. Because it was expensive to produce and typically collected by government agencies or private companies, it was generally restricted to official use or available only at a high cost. However, over the past 15 years, there has been a dramatic shift in the amount of free geospatial data available, from both authoritative institutions and grassroots, academic, crowdsourced, or open-source initiatives.. This shift is due not only to the increase in data being collected, but also a growing public demand for data accessibility. The Open Data movement argues that data, especially data collected by government institutions,  should be available for anyone to access, use, and share. The movement promotes transparency, accountability, and innovation by reducing barriers to information.\nAs a result of these factors, public geospatial data portals have emerged at the local, state, and federal levels. In North Carolina, for instance, platforms like NC OneMap and Chapel Hill Open Data Portal make a wide range of GIS data available to the public. These resources have begun to democratize access to spatial information, enabling broader participation in spatial analysis and decision-making.\nFor critical GIS work, this shift is especially significant. Open data initiatives have helped broaden who can produce and interpret spatial data. However, critical questions remain. Open data is often unevenly distributed, reflecting the priorities, resources, and biases of those who collect and curate it. Increased access does not automatically translate into equity- issues of power, control, and representation continue to shape the geospatial landscape.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "core.html#cooked-data",
    "href": "core.html#cooked-data",
    "title": "3  What is Geographic Data?",
    "section": "3.6 Cooked Data",
    "text": "3.6 Cooked Data\nAs D’Ignazio and Klein (2023) write in Data Feminism, “data are not neutral or objective. They are the products of unequal social relations.” Contrary to the “god-trick”, which Haraway (2013) argues assumes that knowledge can be produced by “seeing everywhere from nowhere”, data is shaped by human decisions. There is no such thing as “raw” data, and recognizing that data is “cooked” means recognizing that data is shaped by the tools, priorities, and power structures of its creators. Data Feminism outlines seven principles for rethinking data practices through a lens of justice and equity. These principles offer a framework for critically engaging with geospatial data:\n\nExamine power: Consider who has the power to produce data and what data is considered useful/useable\nChallenge power: Use data to confront and dismantle unjust systems, not reinforce them\nElevate emotion and embodiment: Value lived experience and emotional knowledge\nRethink binaries and hierarchies: Question categorical simplifications (like male/female, urban/rural)\nEmbrace pluralism: Include diverse voices, community knowledge, and multiple ways of knowing\nConsider context: Understand that data never exists outside of the context in which it was created\nMake labor visible: Acknowledge the work that goes into data collection, cleaning, analysis, and maintenance.\n\nAs we’ll see in the examples below, spatial data (and data generally) often carries embedded assumptions that should be foregrounded in analyses using that data.  \n\n3.6.1 Census Race/Ethnicity Categories\nRacial and ethnic categories in the U.S. Census don’t just reflect reality, they help construct it. These categories aren’t fixed or neutral; they’ve changed over time in response to political, social, and institutional pressures. Once in place, these classifications are used to enforce laws, allocate resources, and shape policy. In GIS and other forms of spatial analysis, census categories often serve as the foundation for mapping demographic patterns, identifying disparities, and informing decisions. But because these categories are treated as fixed units of analysis, the political and historical choices behind them are often overlooked. Over time, they become treated as objective truths rather than socially constructed decisions shaped by specific contexts.\nRead: Strmic-Pawl, Hephzibah V., Brandon A. Jackson, and Steve Garner. “Race counts: racial and ethnic data on the US Census and the implications for tracking inequality.” Sociology of Race and Ethnicity 4, no. 1 (2018): 1-13.\n\n\n3.6.2 Predictive Policing Algorithms\nPredictive policing algorithms use historical crime data to forecast where future crimes might occur. But this data often reflects biased policing practices, not actual patterns of crime. If certain neighborhoods (often Black or brown, low-income communities) were overpoliced in the past, those same areas are flagged again, leading to further policing. This creates a feedback loop where bias in the input data reinforces and reproduces over-policing, which creates additional data bias. \nRead: Karppi, Tero. ““The computer said so”: On the ethics, effectiveness, and cultural techniques of predictive policing.” Social media+ society 4, no. 2 (2018): 2056305118768296.\n\n\n3.6.3 Using Social Media for Disaster Response\nSocial media data is often used to analyze how people experience, respond to, and recover from disasters. However, this data is inherently incomplete– not everyone has access to a phone or social media– and biased, as those who do are not representative of the broader population. It is also frequently used without the informed consent of the individuals who shared it.\nRead: Crawford, Kate, and Megan Finn. “The limits of crisis data: analytical and ethical challenges of using social and mobile data to understand disasters.” GeoJournal 80 (2015): 491-502.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "core.html#ethics-and-privacy",
    "href": "core.html#ethics-and-privacy",
    "title": "3  What is Geographic Data?",
    "section": "3.7 Ethics and Privacy",
    "text": "3.7 Ethics and Privacy\nThe collection and utilization of geospatial data has raised longstanding ethical concerns, particularly around surveillance, privacy, consent, and the uneven distribution of risk. As critical GIS scholars have noted, GIS technologies have their roots in surveillance, and have always been used to serve state and military interests. These origins persist in contemporary applications, where spatial data is often used to track, predict, and regulate human behavior. Scholars have emphasized that these practices risk reinforcing structural inequities, as data infrastructures disproportionately expose marginalized communities to surveillance, profiling, or exclusion.\nIn the era of big data, privacy concerns have deepened. Vast quantities of location data are now collected passively through smartphones, apps, wearable devices, and social media platforms. These data are often repurposed for uses never disclosed to the individuals they describe and users are often unaware that their data is being collected. Even when anonymized, spatial data can often be de-anonymized, especially when combined with other datasets. Locational data is inherently sensitive because it reveals information about personal movement.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "core.html#critical-questions-to-ask-about-your-data",
    "href": "core.html#critical-questions-to-ask-about-your-data",
    "title": "3  What is Geographic Data?",
    "section": "3.8 Critical questions to ask about your data",
    "text": "3.8 Critical questions to ask about your data\n\nWho/what is missing from this data?\nWho decided what to measure and how to measure it?\nHow were the data collected?\nWhat assumptions are built into the data structure?\nWhat is the purpose of this data- and who benefits?\nWhat impacts might my use of the data have? \n\n\n\n\n\nD’Ignazio, Catherine, and Lauren F Klein. 2023. Data Feminism. London, England: MIT Press.\n\n\nHaraway, Donna. 2013. “Rethinking Cyberfeminism(s): Race, Gender, and Embodiment.” In Women, Science, and Technology, 387–403. Routledge. https://doi.org/10.4324/9780203427415-33.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "core.html#toblers-first-law-of-geography",
    "href": "core.html#toblers-first-law-of-geography",
    "title": "3  Core Spatial Concepts",
    "section": "",
    "text": "Tobler’s First Law, Credit: Figure 2.1 from Spatial is Special CC BY-NC-SA 4.0",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#distance-decay",
    "href": "core.html#distance-decay",
    "title": "3  Core Spatial Concepts",
    "section": "3.2 Distance decay",
    "text": "3.2 Distance decay\n Distance decay is the concept that underpins Tobler’s First Law of Geography. Distance decay describes the tendency for interaction between two things to decrease as the distance between them increases. This pattern is driven by the friction of distance (the idea that distance imposes a cost) whether in time, money, or effort, which in turn reduces the likelihood of interaction. For example, consider how you choose a grocery store. If two stores are similar in price and quality, you are more likely to visit the one that is closer, because it costs less time and fuel to reach. However, this example also highlights that friction of distance can be modified. You might willingly travel farther to visit a store that has a product that you can’t get at your local store, which illustrates that the strength of distance decay depends on context and motivation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#spatial-autocorrelation",
    "href": "core.html#spatial-autocorrelation",
    "title": "3  Core Spatial Concepts",
    "section": "3.3 Spatial autocorrelation",
    "text": "3.3 Spatial autocorrelation\nSpatial autocorrelation describes the degree to which values observed at nearby locations are similar (positive autocorrelation) or dissimilar (negative autocorrelation). It reflects the principle that spatial data are not independent- nearby places often share similar characteristics. For example, it is more likely for adjacent neighborhoods to have similar home prices than two neighborhoods on the opposite sides of town. Ignoring spatial autocorrelation can lead to biased or misleading results in statistical analysis because standard models assume independence between observations.\n\n\n\nSpatial Autocorrelation, Credit: Introduction to GIS and Spatial Analysis CC BY-NC-SA 4.0",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#scale",
    "href": "core.html#scale",
    "title": "3  Core Spatial Concepts",
    "section": "3.4 Scale",
    "text": "3.4 Scale\nScale refers to the spatial or temporal level at which data are collected or mapped. Cartographic scale refers to the relationship between distance on the ground and distance on the map. A small-scale map covers a larger geographic area and a large-scale map covers a smaller geographic area. This confusing terminology is due to the fact that this is defined based on the representative fraction, which represents the ratio of a map unit to a unit on earth (for instance 1in:5000ft vs 1in:500ft). Spatial scale refers to the size of the geographic unit (for example, analyzing neighborhoods vs. states) and the spatial extent of the analysis. Read why spatial scale is important here",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#modifiable-areal-unit-problem",
    "href": "core.html#modifiable-areal-unit-problem",
    "title": "3  Core Spatial Concepts",
    "section": "3.5 Modifiable Areal Unit Problem",
    "text": "3.5 Modifiable Areal Unit Problem\nThe Modifiable Areal Unit Problem (MAUP) refers to the bias that can occur when point-based/individual level data are aggregated into spatial units like zip codes, census tracts, or counties. The patterns and results of a spatial analysis can change significantly depending on how the boundaries are drawn (zoning effect) and how large or small the units are (scale effect).\nFor example, calculating the average income of a population using census tracts may yield different patterns than calculating the same average using counties even if both are using the same underlying household-level data (scale effect). A common example of the zone effect is redistricting, where voting districts are redrawn, often in response to population changes, but where different ways of grouping the same population can significantly alter political outcomes.\nConsider the summary statistics for percent poverty across North Carolina zip codes vs. counties to see the impact of the scale effect:\n\n\n\n\n\n\n\n\n\n\n\nAggregation Unit\nMean\nMedian\nMin\nMax\nStandard Deviation\n\n\n\n\nZip Code\n25.22\n23.76\n0\n100\n13.82\n\n\nCounty\n226.46\n25.48\n12.34\n40.83\n6.58\n\n\n\n\n\n\nZone Effect, Credit: User:Andresswift, CC BY 3.0, via Wikimedia Commons\n\n\nThe MAUP matters because most spatial data analysis relies on aggregated units, which are often arbitrarily or administratively defined, not necessarily aligned with meaningful social, environmental, or economic boundaries.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#spatial-hierarchies",
    "href": "core.html#spatial-hierarchies",
    "title": "3  Core Spatial Concepts",
    "section": "3.6 Spatial hierarchies",
    "text": "3.6 Spatial hierarchies\nSpatial hierarchies refer to the idea that we can often organize geographies within nested levels. For instance, city blocks within a neighborhood within a city within a state. These hierarchies often shape how spatial processes operate across space/scale- some phenomena are localized, while others operate at broader scales.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#ecological-fallacy",
    "href": "core.html#ecological-fallacy",
    "title": "3  Core Spatial Concepts",
    "section": "3.7 Ecological fallacy",
    "text": "3.7 Ecological fallacy\nThe ecological fallacy occurs when analyses draw conclusions about individuals based on aggregate data for a group or area.  For instance, knowing that a neighborhood has a high unemployment rate does not mean everyone who lives there is unemployed.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#edge-effects",
    "href": "core.html#edge-effects",
    "title": "3  Core Spatial Concepts",
    "section": "3.8 Edge effects",
    "text": "3.8 Edge effects\nEdge effects refer to the distortions or inaccuracies that occur at the boundaries of a study area. When a study region is artificially cut off, important relationships or influences from outside the boundary may be ignored, leading to misleading conclusions. For example, a pollution study limited to county borders may miss the upstream source of a contaminant. Edge effects are particularly problematic in environmental, ecological, and neighborhood analyses, where spatial context beyond the border often matters.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#spatial-non-stationarity",
    "href": "core.html#spatial-non-stationarity",
    "title": "3  Core Spatial Concepts",
    "section": "3.9 Spatial non-stationarity",
    "text": "3.9 Spatial non-stationarity\nSpatial non-stationarity means that the relationship between variables changes over space. For example, the relationship between income and education may be strong in one North Carolina county and weak in another. Traditional statistical methods assume consistent relationships, but since spatial data often violate this assumption there are techniques like Geographically Weighted Regression (GWR) that are designed to account for spatial non-stationarity by allowing coefficients to vary across space.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "core.html#location-place-and-territory",
    "href": "core.html#location-place-and-territory",
    "title": "3  Core Spatial Concepts",
    "section": "3.10 Location, place, and territory",
    "text": "3.10 Location, place, and territory\nLocation refers to the position of something on the Earth’s surface, either in absolute terms (e.g., coordinates) or relative to other features (e.g., “north of here”). Place goes beyond location to include the meanings, experiences, and emotional attachments people associate with a space. Territory refers to a bounded area that is claimed, governed, controlled, or contested.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Core Spatial Concepts</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "4  What is Geographic Data?",
    "section": "",
    "text": "4.1 Defining Geographic Data and Information\nThis chapter will introduce geographic data, where it comes from, and how it is produced.\nGeographic data is data that can be tied to a specific location on Earth. In general, geographic data includes both location and attribute components. The location tells us where a feature is in the world and must be represented using a coordinate system, which provides a standardized way of expressing position on the Earth’s surface (hello Cartesian logic!), to be analyzed in a GIS. The attributes provide additional information about what exists or occurs at that location. Geographic data can be stored in a variety of formats, which will be explored in greater detail in Chapter 5, and can represent both physical and human features, such as rivers, roads, buildings, vegetation, population density, pollution levels, or disease clusters. In particular, GIS is used to turn data into information. “Raw” data must be processed, analyzed, and contextualized to become information.\nData quality is the foundation of any successful analysis. To produce meaningful results, the data you use must be temporally suitable, appropriately detailed, and relevant to your spatial question. If the resolution is too coarse, the data outdated, or the attributes inaccurate, your analysis will be compromised. As the saying goes, “Garbage in, garbage out”- the quality of your output is only as good as the quality of your input.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#where-does-geographic-data-come-from-and-how-is-it-collected",
    "href": "data.html#where-does-geographic-data-come-from-and-how-is-it-collected",
    "title": "4  What is Geographic Data?",
    "section": "4.2 Where does geographic data come from and how is it collected ",
    "text": "4.2 Where does geographic data come from and how is it collected \nHistorically, geospatial data was collected almost exclusively by state institutions, militaries, and professional surveyors. These data sources were considered “authoritative” because they relied on credentialed experts, standardized tools, and formal methodologies to achieve a high degree of accuracy. Early data collection involved resource-intensive methods like land surveying (using total stations and reference points), aerial photography for photogrammetry, remote sensing, and field data collection during censuses. The tools were expensive, slow, and required specialized training, but they produced high-quality data with thorough documentation (metadata). At the same time, they necessarily represented and re-created the priorities of those funding its acquisition. \nSome of the common sources of “authoritative” spatial data include: \n\nUS Census Bureau\n\nPopulation counts and demographics (e.g., race, age, income)\nHousing and economic data\nGeographic boundaries (e.g., census tracts, block groups, ZIP code tabulation areas)\n\nUS Geological Survey (USGS) \n\nTopographic maps\nElevation and terrain (e.g., DEMs)\nLand cover and land use (e.g., NLCD)\nHydrography (rivers, lakes, watersheds)\nGeologic and seismic data\n\nNASA\n\nWeather and climate data\nCoastal and marine mapping (e.g., nautical charts, sea surface temperature)\nFlood zones and storm surge models\nFisheries and oceanographic data\n\nState and Local Governments\n\nParcel and zoning data\nTransportation networks (roads, transit routes)\nUtilities and infrastructure (e.g., water lines, sewer systems)\nLand use plans and municipal boundaries\n\nEPA\n\nAir and water quality data\nEnvironmental justice mapping (e.g., EJScreen)\nRegulated facility locations",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#collection-methods",
    "href": "data.html#collection-methods",
    "title": "4  What is Geographic Data?",
    "section": "4.3 Collection methods",
    "text": "4.3 Collection methods\n\n4.3.1 Remote sensing\nUses satellites or aircraft to capture reflected or emitted energy from the Earth’s surface. Because different surfaces reflect energy at different wavelengths, this method can be used to identify and classify surfaces on earth.\n\n\n\nRemote Sensing, Credit: Arkarjun, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\n\n4.3.2 Land Surveys\nSurveying is a method of collecting highly accurate location data by measuring distances and angles between known points on the ground. Surveyors often use tools like total stations, which send laser signals to a reflective prism to calculate distance and direction, or survey-grade GPS units that use satellite signals with corrections from nearby base stations to achieve centimeter-level accuracy. By combining these measurements with known reference points (control points), surveyors can calculate the precise coordinates of new locations. \n\n\n\nLand Survey Equipment, Credit: Bureau of Land Management Oregon and Washington, Public domain, via Wikimedia Commons\n\n\n\n\n4.3.3 Sensors\nSensors are placed in fixed locations and are typically used to collect environmental data, such as air pollution, rainfall, or noise levels, over short or extended periods of time. For instance, the national ASOS/AWOS network consists of over 900 stations across the US collecting weather data for over 30 years. \n\n\n\nAWOS Station, Credit: Famartin, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\n\n4.3.4 GPS/GNSS\nGPS works through trilateration, which determines location by measuring distances from multiple satellites. Each satellite sends a signal with the time it was sent which allows GPS devices on the ground to calculate how far the satellite is from the device location. With signals from at least four satellites, the GPS receiver can determine your exact position on Earth (latitude, longitude, and elevation). GPS uses only the US satellite network, GNSS uses the global network.\n\n\n\nTrilateration, Credit: Javiersanp, CC BY-SA 4.0, via Wikimedia Commons\n\n\n\n\n4.3.5 Aerial Photography\nImages captured from planes or drones are used to document the Earth’s surface\n\n\n\nImagery Collected after Hurricane Helene, Credit: NOAA\n\n\n\n\n4.3.6 LiDAR (Light Detection and Ranging)\nLiDAR uses rapid laser pulses from aircraft or drones to measure the distance to the ground. By calculating how long it takes the light to bounce back, LiDAR can produce highly detailed 3D models. \n\n\n4.3.7 Photogrammetry\nPhotogrammetry involves taking many overlapping images of the same area, usually from drones or aircraft, and using software to extract depth, shape, and spatial relationships. It’s commonly used for creating orthophotos, elevation models, and 3D reconstructions.\n\n\n\nPhotogrammetry, Credit: NELAC , CC BY-SA 4.0, via Wikimedia Commons\n\n\n\n\n4.3.8 Census and Surveys\nThese methods gather demographic, social, and economic data directly from people through questionnaires, interviews, or field observations. The U.S. Census, for example, collects data on population, housing, and income and ties this information to geographic areas for mapping and policy use.\n\n\n4.3.9 Could Be Spatial Data\nMany data sources contain locational information, even if geography is not their primary focus. For example, health records often include patient zip codes, census tracts, or home addresses; tax documents may list property locations or mailing addresses; school enrollment data might be tied to district boundaries or bus routes. While these datasets are not explicitly spatial in origin, they become spatial when analyzed through the lens of geography.\n\n\n4.3.10 New Sources of Geographic Data\nCollecting geospatial data is now easier than ever. Almost every smartphone has built-in GPS/GNSS. Instead of the ability to collect geospatial data being relatively restricted, it is now possible for nearly anyone to record geographic data. In addition, the rise of online mapping tools like Google Earth has also made geospatial technologies more accessible to the public. As a result, geospatial data collection is no longer confined to experts or specialized equipment, leading to an explosion in the amount of data being generated. These crowdsourced and citizen-generated datasets are now used to support everything from disaster response to urban planning.\nSome well-known examples include:\n\nOpenStreetMap: A free, crowdsourced map of the world built by millions of contributors, widely used in humanitarian efforts and mapping underserved areas.\nMapillary: A platform where users upload street-level imagery to support navigation, urban development, and computer vision training.\neBird: A citizen science project where birdwatchers record sightings, contributing to biodiversity monitoring and conservation.\niNaturalist: A platform where people document observations of plants and animals, helping scientists track species distribution and ecological change.\n\nCrowdsourced or community-collected geospatial data has become an increasingly important way to capture information that is intentionally or unintentionally missed by “authoritative” sources. These grassroots efforts often seek to fill data gaps that disproportionately affect marginalized communities. However, the rise of crowdsourced data has also created tension between official and unofficial sources, which has raised questions about what kinds of data are considered legitimate and who is qualified to collect them. \n\n\n4.3.11 Case Study\nLouisiana Bans Community Air Quality Data\nIn Louisiana, particularly in the heavily industrialized region known as “Cancer Alley”, residents have been raising concerns about high levels of pollution near industrial facilities. A lack of “authoritative” air pollution data in the area (due to the EPA’s sparse and unevenly distributed monitoring network) meant that community members were unable to validate their concerns. In response, community members began using low-cost air quality sensors to collect their own data. \nHowever, in May 2023, Louisiana passed legislation banning the use of community-collected air quality data in legal or regulatory processes. Lawmakers justified the ban by citing concerns about the accuracy, calibration, and scientific rigor of the sensors used. This decision effectively invalidated grassroots efforts to document environmental health risks and reinforced institutional control over which data “counts.” It also revealed deeper tensions around participatory data, raising questions about who defines data quality, how metadata and standards are used to include or exclude information.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#metadata",
    "href": "data.html#metadata",
    "title": "4  What is Geographic Data?",
    "section": "4.5 Metadata",
    "text": "4.5 Metadata\nMetadata adds context to a geographic dataset by providing information on how, why, when, and by whom geographic data were collected. Understanding this context is essential for determining whether a dataset can/should be used in a certain analysis. In particular, metadata should answer the following questions:\n\nWhat is this data about?\nWhere did it come from?\nWhen was it gathered?\nHow is it organized?\nHow is it located on earth? \nWhat features does this data describe and in how much detail?\nWhat kind of features does this data set describe and in how much detail?\nWho documented the data? \n\nGeospatial metadata is often stored using standardized formats that are structured in XML. There are different metadata standards- such as FGDC (Federal Geographic Data Committee) or ISO 19115- which define consistent ways to create metadata. Metadata is typically embedded within the data file itself (like in a GeoTIFF), stored alongside it as an auxiliary XML file, or managed in a separate metadata catalog or database.\nAt the same time, metadata often acts as a kind of “gatekeeper” to authoritative spatial data sources, acting as a determining factor to what data is considered trustworthy, usable, or legitimate. A lack of standardized metadata is frequently used as a reason to dismiss crowdsourced or community-collected data, regardless of its relevance or local accuracy. In this way, metadata standards can reinforce institutional control over which data counts and whose knowledge is valued.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#open-data",
    "href": "data.html#open-data",
    "title": "4  What is Geographic Data?",
    "section": "4.6 Open Data",
    "text": "4.6 Open Data\nUntil recently, most geospatial data was difficult for the public to access. Because it was expensive to produce and typically collected by government agencies or private companies, it was generally restricted to official use or available only at a high cost. However, over the past 15 years, there has been a dramatic shift in the amount of free geospatial data available, from both authoritative institutions and grassroots, academic, crowdsourced, or open-source initiatives.. This shift is due not only to the increase in data being collected, but also a growing public demand for data accessibility. The Open Data movement argues that data, especially data collected by government institutions,  should be available for anyone to access, use, and share. The movement promotes transparency, accountability, and innovation by reducing barriers to information.\nAs a result of these factors, public geospatial data portals have emerged at the local, state, and federal levels. In North Carolina, for instance, platforms like NC OneMap and Chapel Hill Open Data Portal make a wide range of GIS data available to the public. These resources have begun to democratize access to spatial information, enabling broader participation in spatial analysis and decision-making.\nFor critical GIS work, this shift is especially significant. Open data initiatives have helped broaden who can produce and interpret spatial data. However, critical questions remain. Open data is often unevenly distributed, reflecting the priorities, resources, and biases of those who collect and curate it. Increased access does not automatically translate into equity- issues of power, control, and representation continue to shape the geospatial landscape.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#cooked-data",
    "href": "data.html#cooked-data",
    "title": "4  What is Geographic Data?",
    "section": "4.7 Cooked Data",
    "text": "4.7 Cooked Data\nAs D’Ignazio and Klein (2023) write in Data Feminism, “data are not neutral or objective. They are the products of unequal social relations.” Contrary to the “god-trick”, which Haraway (2013) argues assumes that knowledge can be produced by “seeing everywhere from nowhere”, data is shaped by human decisions. There is no such thing as “raw” data, and recognizing that data is “cooked” means recognizing that data is shaped by the tools, priorities, and power structures of its creators. Data Feminism outlines seven principles for rethinking data practices through a lens of justice and equity. These principles offer a framework for critically engaging with geospatial data:\n\nExamine power: Consider who has the power to produce data and what data is considered useful/useable\nChallenge power: Use data to confront and dismantle unjust systems, not reinforce them\nElevate emotion and embodiment: Value lived experience and emotional knowledge\nRethink binaries and hierarchies: Question categorical simplifications (like male/female, urban/rural)\nEmbrace pluralism: Include diverse voices, community knowledge, and multiple ways of knowing\nConsider context: Understand that data never exists outside of the context in which it was created\nMake labor visible: Acknowledge the work that goes into data collection, cleaning, analysis, and maintenance.\n\nAs we’ll see in the examples below, spatial data (and data generally) often carries embedded assumptions that should be foregrounded in analyses using that data.  \n\n4.7.1 Census Race/Ethnicity Categories\nRacial and ethnic categories in the U.S. Census don’t just reflect reality, they help construct it. These categories aren’t fixed or neutral; they’ve changed over time in response to political, social, and institutional pressures. Once in place, these classifications are used to enforce laws, allocate resources, and shape policy. In GIS and other forms of spatial analysis, census categories often serve as the foundation for mapping demographic patterns, identifying disparities, and informing decisions. But because these categories are treated as fixed units of analysis, the political and historical choices behind them are often overlooked. Over time, they become treated as objective truths rather than socially constructed decisions shaped by specific contexts.\nRead: Strmic-Pawl, Hephzibah V., Brandon A. Jackson, and Steve Garner. “Race counts: racial and ethnic data on the US Census and the implications for tracking inequality.” Sociology of Race and Ethnicity 4, no. 1 (2018): 1-13.\n\n\n4.7.2 Predictive Policing Algorithms\nPredictive policing algorithms use historical crime data to forecast where future crimes might occur. But this data often reflects biased policing practices, not actual patterns of crime. If certain neighborhoods (often Black or brown, low-income communities) were overpoliced in the past, those same areas are flagged again, leading to further policing. This creates a feedback loop where bias in the input data reinforces and reproduces over-policing, which creates additional data bias. \nRead: Karppi, Tero. ““The computer said so”: On the ethics, effectiveness, and cultural techniques of predictive policing.” Social media+ society 4, no. 2 (2018): 2056305118768296.\n\n\n4.7.3 Using Social Media for Disaster Response\nSocial media data is often used to analyze how people experience, respond to, and recover from disasters. However, this data is inherently incomplete– not everyone has access to a phone or social media– and biased, as those who do are not representative of the broader population. It is also frequently used without the informed consent of the individuals who shared it.\nRead: Crawford, Kate, and Megan Finn. “The limits of crisis data: analytical and ethical challenges of using social and mobile data to understand disasters.” GeoJournal 80 (2015): 491-502.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#ethics-and-privacy",
    "href": "data.html#ethics-and-privacy",
    "title": "4  What is Geographic Data?",
    "section": "4.8 Ethics and Privacy",
    "text": "4.8 Ethics and Privacy\nThe collection and utilization of geospatial data has raised longstanding ethical concerns, particularly around surveillance, privacy, consent, and the uneven distribution of risk. As critical GIS scholars have noted, GIS technologies have their roots in surveillance, and have always been used to serve state and military interests. These origins persist in contemporary applications, where spatial data is often used to track, predict, and regulate human behavior. Scholars (such as Elwood and Leszczynski (2018) and Taylor (2017)) have emphasized that these practices risk reinforcing structural inequities, as data infrastructures disproportionately expose marginalized communities to surveillance, profiling, or exclusion.\nIn the era of big data, privacy concerns have deepened. Vast quantities of location data are now collected passively through smartphones, apps, wearable devices, and social media platforms. These data are often repurposed for uses never disclosed to the individuals they describe and users are often unaware that their data is being collected. Even when anonymized, spatial data can often be de-anonymized, especially when combined with other datasets. Locational data is inherently sensitive because it reveals information about personal movement.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#critical-questions-to-ask-about-your-data",
    "href": "data.html#critical-questions-to-ask-about-your-data",
    "title": "4  What is Geographic Data?",
    "section": "4.9 Critical questions to ask about your data",
    "text": "4.9 Critical questions to ask about your data\n\nWho/what is missing from this data?\nWho decided what to measure and how to measure it?\nHow were the data collected?\nWhat assumptions are built into the data structure?\nWhat is the purpose of this data- and who benefits?\nWhat impacts might my use of the data have? \n\n\n\n\n\nD’Ignazio, Catherine, and Lauren F Klein. 2023. Data Feminism. London, England: MIT Press.\n\n\nElwood, Sarah, and Agnieszka Leszczynski. 2018. “Feminist Digital Geographies.” Gender, Place and Culture: A Journal of Feminist Geography 25 (5): 629–44. https://doi.org/10.1080/0966369x.2018.1465396.\n\n\nHaraway, Donna. 2013. “Rethinking Cyberfeminism(s): Race, Gender, and Embodiment.” In Women, Science, and Technology, 387–403. Routledge. https://doi.org/10.4324/9780203427415-33.\n\n\nTaylor, Linnet. 2017. “What Is Data Justice? The Case for Connecting Digital Rights and Freedoms Globally.” Big Data & Society 4 (2): 205395171773633. https://doi.org/10.1177/2053951717736335.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "5  Spatial Data Models",
    "section": "",
    "text": "5.1 Vector Models\nWhen translating real-world features into geographic data, there are two main “conceptual” views of the world: the field view and the object view. A field view treats the world as a continuous surface, where each location is associated with one or more attributes. In contrast, an object view conceptualizes the world as made up of discrete entities that have clearly defined boundaries and exist in specific locations. Between these objects, there can be empty space with no associated features.\nThese conceptual models align with two major data models used in GIS. A vector-based model represents geographic features as sets of points, lines, or polygons. This is well-suited for discrete objects. A raster-based model, on the other hand, represents space as a grid of regularly spaced cells, each containing a value that represents an attribute at that location. This structure is ideal for continuous data, where each cell captures a small piece of a surface.\nTogether, these models allow geographers to choose the most appropriate representation depending on the nature of the phenomenon being studied. The selection of data model then impacts what kinds of spatial questions can be asked about the data, what analysis operations are possible on the data, and how patterns and relationships are interpreted across space.\nVector data is built around geometries, which are encoded into the file. The most basic geometry type is a point. A point is represented as a single coordinate pair (x, y).\nPoints can then be combined to create lines and polygons. To create a line, at least two distinct points must be connected\nA polygon is created when three or more line segments are connected which means the starting and ending coordinate pairs must be the same. Of the three basic geometric primitives (point, line, polygon), only polygons have an area.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Data Models</span>"
    ]
  },
  {
    "objectID": "models.html#where-does-geographic-data-come-from-and-how-is-it-collected",
    "href": "models.html#where-does-geographic-data-come-from-and-how-is-it-collected",
    "title": "5  What is Geographic Data?",
    "section": "5.2 Where does geographic data come from and how is it collected ",
    "text": "5.2 Where does geographic data come from and how is it collected \nHistorically, geospatial data was collected almost exclusively by state institutions, militaries, and professional surveyors. These data sources were considered “authoritative” because they relied on credentialed experts, standardized tools, and formal methodologies to achieve a high degree of accuracy. Early data collection involved resource-intensive methods like land surveying (using total stations and reference points), aerial photography for photogrammetry, remote sensing, and field data collection during censuses. The tools were expensive, slow, and required specialized training, but they produced high-quality data with thorough documentation (metadata). At the same time, they necessarily represented and re-created the priorities of those funding its acquisition. \nSome of the common sources of “authoritative” spatial data include: \n\nUS Census Bureau\n\nPopulation counts and demographics (e.g., race, age, income)\nHousing and economic data\nGeographic boundaries (e.g., census tracts, block groups, ZIP code tabulation areas)\n\nUS Geological Survey (USGS) \n\nTopographic maps\nElevation and terrain (e.g., DEMs)\nLand cover and land use (e.g., NLCD)\nHydrography (rivers, lakes, watersheds)\nGeologic and seismic data\n\nNASA\n\nWeather and climate data\nCoastal and marine mapping (e.g., nautical charts, sea surface temperature)\nFlood zones and storm surge models\nFisheries and oceanographic data\n\nState and Local Governments\n\nParcel and zoning data\nTransportation networks (roads, transit routes)\nUtilities and infrastructure (e.g., water lines, sewer systems)\nLand use plans and municipal boundaries\n\nEPA\n\nAir and water quality data\nEnvironmental justice mapping (e.g., EJScreen)\nRegulated facility locations",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "models.html#collection-methods",
    "href": "models.html#collection-methods",
    "title": "5  What is Geographic Data?",
    "section": "5.3 Collection methods",
    "text": "5.3 Collection methods\n\n5.3.1 Remote sensing\nUses satellites or aircraft to capture reflected or emitted energy from the Earth’s surface. Because different surfaces reflect energy at different wavelengths, this method can be used to identify and classify surfaces on earth.\n\n\n\nRemote Sensing, Credit: Arkarjun, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\n\n5.3.2 Land Surveys\nSurveying is a method of collecting highly accurate location data by measuring distances and angles between known points on the ground. Surveyors often use tools like total stations, which send laser signals to a reflective prism to calculate distance and direction, or survey-grade GPS units that use satellite signals with corrections from nearby base stations to achieve centimeter-level accuracy. By combining these measurements with known reference points (control points), surveyors can calculate the precise coordinates of new locations. \n\n\n\nLand Survey Equipment, Credit: Bureau of Land Management Oregon and Washington, Public domain, via Wikimedia Commons\n\n\n\n\n5.3.3 Sensors\nSensors are placed in fixed locations and are typically used to collect environmental data, such as air pollution, rainfall, or noise levels, over short or extended periods of time. For instance, the national ASOS/AWOS network consists of over 900 stations across the US collecting weather data for over 30 years. \n\n\n\nAWOS Station, Credit: Famartin, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\n\n5.3.4 GPS/GNSS\nGPS works through trilateration, which determines location by measuring distances from multiple satellites. Each satellite sends a signal with the time it was sent which allows GPS devices on the ground to calculate how far the satellite is from the device location. With signals from at least four satellites, the GPS receiver can determine your exact position on Earth (latitude, longitude, and elevation). GPS uses only the US satellite network, GNSS uses the global network.\n\n\n\nTrilateration, Credit: Javiersanp, CC BY-SA 4.0, via Wikimedia Commons\n\n\n\n\n5.3.5 Aerial Photography\nImages captured from planes or drones are used to document the Earth’s surface\n\n\n\nImagery Collected after Hurricane Helene, Credit: NOAA\n\n\n\n\n5.3.6 LiDAR (Light Detection and Ranging)\nLiDAR uses rapid laser pulses from aircraft or drones to measure the distance to the ground. By calculating how long it takes the light to bounce back, LiDAR can produce highly detailed 3D models. \n\n\n5.3.7 Photogrammetry\nPhotogrammetry involves taking many overlapping images of the same area, usually from drones or aircraft, and using software to extract depth, shape, and spatial relationships. It’s commonly used for creating orthophotos, elevation models, and 3D reconstructions.\n\n\n\nPhotogrammetry, Credit: NELAC , CC BY-SA 4.0, via Wikimedia Commons\n\n\n\n\n5.3.8 Census and Surveys\nThese methods gather demographic, social, and economic data directly from people through questionnaires, interviews, or field observations. The U.S. Census, for example, collects data on population, housing, and income and ties this information to geographic areas for mapping and policy use.\n\n\n5.3.9 Could Be Spatial Data\nMany data sources contain locational information, even if geography is not their primary focus. For example, health records often include patient zip codes, census tracts, or home addresses; tax documents may list property locations or mailing addresses; school enrollment data might be tied to district boundaries or bus routes. While these datasets are not explicitly spatial in origin, they become spatial when analyzed through the lens of geography.\n\n\n5.3.10 New Sources of Geographic Data\nCollecting geospatial data is now easier than ever. Almost every smartphone has built-in GPS/GNSS. Instead of the ability to collect geospatial data being relatively restricted, it is now possible for nearly anyone to record geographic data. In addition, the rise of online mapping tools like Google Earth has also made geospatial technologies more accessible to the public. As a result, geospatial data collection is no longer confined to experts or specialized equipment, leading to an explosion in the amount of data being generated. These crowdsourced and citizen-generated datasets are now used to support everything from disaster response to urban planning.\nSome well-known examples include:\n\nOpenStreetMap: A free, crowdsourced map of the world built by millions of contributors, widely used in humanitarian efforts and mapping underserved areas.\nMapillary: A platform where users upload street-level imagery to support navigation, urban development, and computer vision training.\neBird: A citizen science project where birdwatchers record sightings, contributing to biodiversity monitoring and conservation.\niNaturalist: A platform where people document observations of plants and animals, helping scientists track species distribution and ecological change.\n\nCrowdsourced or community-collected geospatial data has become an increasingly important way to capture information that is intentionally or unintentionally missed by “authoritative” sources. These grassroots efforts often seek to fill data gaps that disproportionately affect marginalized communities. However, the rise of crowdsourced data has also created tension between official and unofficial sources, which has raised questions about what kinds of data are considered legitimate and who is qualified to collect them. \n\n\n5.3.11 Case Study\nLouisiana Bans Community Air Quality Data\nIn Louisiana, particularly in the heavily industrialized region known as “Cancer Alley”, residents have been raising concerns about high levels of pollution near industrial facilities. A lack of “authoritative” air pollution data in the area (due to the EPA’s sparse and unevenly distributed monitoring network) meant that community members were unable to validate their concerns. In response, community members began using low-cost air quality sensors to collect their own data. \nHowever, in May 2023, Louisiana passed legislation banning the use of community-collected air quality data in legal or regulatory processes. Lawmakers justified the ban by citing concerns about the accuracy, calibration, and scientific rigor of the sensors used. This decision effectively invalidated grassroots efforts to document environmental health risks and reinforced institutional control over which data “counts.” It also revealed deeper tensions around participatory data, raising questions about who defines data quality, how metadata and standards are used to include or exclude information.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "models.html#metadata",
    "href": "models.html#metadata",
    "title": "5  What is Geographic Data?",
    "section": "5.4 Metadata",
    "text": "5.4 Metadata\nMetadata adds context to a geographic dataset by providing information on how, why, when, and by whom geographic data were collected. Understanding this context is essential for determining whether a dataset can/should be used in a certain analysis. In particular, metadata should answer the following questions:\n\nWhat is this data about?\nWhere did it come from?\nWhen was it gathered?\nHow is it organized?\nHow is it located on earth? \nWhat features does this data describe and in how much detail?\nWhat kind of features does this data set describe and in how much detail?\nWho documented the data? \n\nGeospatial metadata is often stored using standardized formats that are structured in XML. There are different metadata standards- such as FGDC (Federal Geographic Data Committee) or ISO 19115- which define consistent ways to create metadata. Metadata is typically embedded within the data file itself (like in a GeoTIFF), stored alongside it as an auxiliary XML file, or managed in a separate metadata catalog or database.\nAt the same time, metadata often acts as a kind of “gatekeeper” to authoritative spatial data sources, acting as a determining factor to what data is considered trustworthy, usable, or legitimate. A lack of standardized metadata is frequently used as a reason to dismiss crowdsourced or community-collected data, regardless of its relevance or local accuracy. In this way, metadata standards can reinforce institutional control over which data counts and whose knowledge is valued.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "models.html#open-data",
    "href": "models.html#open-data",
    "title": "5  What is Geographic Data?",
    "section": "5.5 Open Data",
    "text": "5.5 Open Data\nUntil recently, most geospatial data was difficult for the public to access. Because it was expensive to produce and typically collected by government agencies or private companies, it was generally restricted to official use or available only at a high cost. However, over the past 15 years, there has been a dramatic shift in the amount of free geospatial data available, from both authoritative institutions and grassroots, academic, crowdsourced, or open-source initiatives.. This shift is due not only to the increase in data being collected, but also a growing public demand for data accessibility. The Open Data movement argues that data, especially data collected by government institutions,  should be available for anyone to access, use, and share. The movement promotes transparency, accountability, and innovation by reducing barriers to information.\nAs a result of these factors, public geospatial data portals have emerged at the local, state, and federal levels. In North Carolina, for instance, platforms like NC OneMap and Chapel Hill Open Data Portal make a wide range of GIS data available to the public. These resources have begun to democratize access to spatial information, enabling broader participation in spatial analysis and decision-making.\nFor critical GIS work, this shift is especially significant. Open data initiatives have helped broaden who can produce and interpret spatial data. However, critical questions remain. Open data is often unevenly distributed, reflecting the priorities, resources, and biases of those who collect and curate it. Increased access does not automatically translate into equity- issues of power, control, and representation continue to shape the geospatial landscape.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "models.html#cooked-data",
    "href": "models.html#cooked-data",
    "title": "5  What is Geographic Data?",
    "section": "5.6 Cooked Data",
    "text": "5.6 Cooked Data\nAs D’Ignazio and Klein (2023) write in Data Feminism, “data are not neutral or objective. They are the products of unequal social relations.” Contrary to the “god-trick”, which Haraway (2013) argues assumes that knowledge can be produced by “seeing everywhere from nowhere”, data is shaped by human decisions. There is no such thing as “raw” data, and recognizing that data is “cooked” means recognizing that data is shaped by the tools, priorities, and power structures of its creators. Data Feminism outlines seven principles for rethinking data practices through a lens of justice and equity. These principles offer a framework for critically engaging with geospatial data:\n\nExamine power: Consider who has the power to produce data and what data is considered useful/useable\nChallenge power: Use data to confront and dismantle unjust systems, not reinforce them\nElevate emotion and embodiment: Value lived experience and emotional knowledge\nRethink binaries and hierarchies: Question categorical simplifications (like male/female, urban/rural)\nEmbrace pluralism: Include diverse voices, community knowledge, and multiple ways of knowing\nConsider context: Understand that data never exists outside of the context in which it was created\nMake labor visible: Acknowledge the work that goes into data collection, cleaning, analysis, and maintenance.\n\nAs we’ll see in the examples below, spatial data (and data generally) often carries embedded assumptions that should be foregrounded in analyses using that data.  \n\n5.6.1 Census Race/Ethnicity Categories\nRacial and ethnic categories in the U.S. Census don’t just reflect reality, they help construct it. These categories aren’t fixed or neutral; they’ve changed over time in response to political, social, and institutional pressures. Once in place, these classifications are used to enforce laws, allocate resources, and shape policy. In GIS and other forms of spatial analysis, census categories often serve as the foundation for mapping demographic patterns, identifying disparities, and informing decisions. But because these categories are treated as fixed units of analysis, the political and historical choices behind them are often overlooked. Over time, they become treated as objective truths rather than socially constructed decisions shaped by specific contexts.\nRead: Strmic-Pawl, Hephzibah V., Brandon A. Jackson, and Steve Garner. “Race counts: racial and ethnic data on the US Census and the implications for tracking inequality.” Sociology of Race and Ethnicity 4, no. 1 (2018): 1-13.\n\n\n5.6.2 Predictive Policing Algorithms\nPredictive policing algorithms use historical crime data to forecast where future crimes might occur. But this data often reflects biased policing practices, not actual patterns of crime. If certain neighborhoods (often Black or brown, low-income communities) were overpoliced in the past, those same areas are flagged again, leading to further policing. This creates a feedback loop where bias in the input data reinforces and reproduces over-policing, which creates additional data bias. \nRead: Karppi, Tero. ““The computer said so”: On the ethics, effectiveness, and cultural techniques of predictive policing.” Social media+ society 4, no. 2 (2018): 2056305118768296.\n\n\n5.6.3 Using Social Media for Disaster Response\nSocial media data is often used to analyze how people experience, respond to, and recover from disasters. However, this data is inherently incomplete– not everyone has access to a phone or social media– and biased, as those who do are not representative of the broader population. It is also frequently used without the informed consent of the individuals who shared it.\nRead: Crawford, Kate, and Megan Finn. “The limits of crisis data: analytical and ethical challenges of using social and mobile data to understand disasters.” GeoJournal 80 (2015): 491-502.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "models.html#ethics-and-privacy",
    "href": "models.html#ethics-and-privacy",
    "title": "5  What is Geographic Data?",
    "section": "5.7 Ethics and Privacy",
    "text": "5.7 Ethics and Privacy\nThe collection and utilization of geospatial data has raised longstanding ethical concerns, particularly around surveillance, privacy, consent, and the uneven distribution of risk. As critical GIS scholars have noted, GIS technologies have their roots in surveillance, and have always been used to serve state and military interests. These origins persist in contemporary applications, where spatial data is often used to track, predict, and regulate human behavior. Scholars (such as Elwood and Leszczynski (2018) and Taylor (2017)) have emphasized that these practices risk reinforcing structural inequities, as data infrastructures disproportionately expose marginalized communities to surveillance, profiling, or exclusion.\nIn the era of big data, privacy concerns have deepened. Vast quantities of location data are now collected passively through smartphones, apps, wearable devices, and social media platforms. These data are often repurposed for uses never disclosed to the individuals they describe and users are often unaware that their data is being collected. Even when anonymized, spatial data can often be de-anonymized, especially when combined with other datasets. Locational data is inherently sensitive because it reveals information about personal movement.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "models.html#critical-questions-to-ask-about-your-data",
    "href": "models.html#critical-questions-to-ask-about-your-data",
    "title": "5  What is Geographic Data?",
    "section": "5.8 Critical questions to ask about your data",
    "text": "5.8 Critical questions to ask about your data\n\nWho/what is missing from this data?\nWho decided what to measure and how to measure it?\nHow were the data collected?\nWhat assumptions are built into the data structure?\nWhat is the purpose of this data- and who benefits?\nWhat impacts might my use of the data have? \n\n\n\n\n\nD’Ignazio, Catherine, and Lauren F Klein. 2023. Data Feminism. London, England: MIT Press.\n\n\nElwood, Sarah, and Agnieszka Leszczynski. 2018. “Feminist Digital Geographies.” Gender, Place and Culture: A Journal of Feminist Geography 25 (5): 629–44. https://doi.org/10.1080/0966369x.2018.1465396.\n\n\nHaraway, Donna. 2013. “Rethinking Cyberfeminism(s): Race, Gender, and Embodiment.” In Women, Science, and Technology, 387–403. Routledge. https://doi.org/10.4324/9780203427415-33.\n\n\nTaylor, Linnet. 2017. “What Is Data Justice? The Case for Connecting Digital Rights and Freedoms Globally.” Big Data & Society 4 (2): 205395171773633. https://doi.org/10.1177/2053951717736335.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "making_maps.html",
    "href": "making_maps.html",
    "title": "13  Making Maps",
    "section": "",
    "text": "13.1 Cartography is not neutral\nCartography is the study and practice of making maps. Maps are the most common output of a GIS analysis because they allow you to retain the spatiality of the results. While maps are generally presented as objective versions of reality, they are deeply shaped by social, political, and cultural forces. Critical cartography, which is a companion thread of academic thinking as critical GIS, argues that map creation is a power-laden practice. Although cartography has historically been associated with precision and technical authority, each map reflects the goals of the cartographer, who has the power to pick what is put on a map and how it is represented. Harley (1989), a scholar who is largely credited with the origins of critical cartography, argues that maps are not passive representations of spatial reality, they actively construct the world they describe.\nAs Wood (2003) writes, “maps work”, meaning that they do not simply represent space, but actively shape how space is imagined, governed, and contested. Historically, the authority to create maps belonged to powerful institutions, including imperial governments, military regimes, and national surveying agencies. Cartography was largely a tool of governance, used to inscribe the priorities of those in power onto the landscape. Colonial powers, for instance, employed mapping to fix borders, catalog lands, and make Indigenous territories legible for exploitation. By rendering land as empty, available, or bounded in specific ways, these maps facilitated resource extraction, taxation, settlement, and military control. In many cases, they were also deeply ideological, projecting European spatial norms (grids, parcels, ownership) onto different understandings of space.\nEven in the present, maps continue to legitimize and reinforce dominant spatial orders. State-produced cadastral maps formalize land ownership and enable governance and taxation. Zoning maps shape where homes, businesses, and industry are allowed. Infrastructure planning maps guide decisions about roads, utilities, and development. In these ways, maps remain deeply political, shaping whose spaces are visible, whose knowledge counts, and whose claims to land are recognized or erased.\nIn the past two decades, the rise of digital mapping has redistributed some cartographic power. Now, instead of the state, corporations like Google and Apple are now the dominant producers of maps used in everyday life. Their mapping platforms shape how we navigate, what we see, and what we don’t. Google Maps, for instance, makes decisions about which businesses show up in search results, which routes are recommended, and how disputed territories are labeled. These are not just technical decisions, they are political and social ones made largely outside of the public eye.\nAt the same time, the ability to make maps has become more accessible. With tools like GIS software and OpenStreetMap the public now has far greater capacity to produce spatial data and visualize it. This has led to a proliferation of maps produced outside traditional institutions. The ability to map is no longer limited to the state or to experts. But access doesn’t automatically translate to power. The visibility and influence of a map still depend on its circulation, uptake, and who controls the underlying platforms and data. Therefore, what we’re seeing is not a simple democratization of cartography, but a reconfiguration of its power.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Making Maps</span>"
    ]
  },
  {
    "objectID": "making_maps.html#designing-maps",
    "href": "making_maps.html#designing-maps",
    "title": "13  Making Maps",
    "section": "13.2 Designing Maps",
    "text": "13.2 Designing Maps\nFor this section, I will defer to an excellent open-access textbook\nMaking Effective Maps: Cartographic Visualization for GIS",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Making Maps</span>"
    ]
  },
  {
    "objectID": "making_maps.html#counter-mapping-and-community-mapping",
    "href": "making_maps.html#counter-mapping-and-community-mapping",
    "title": "13  Making Maps",
    "section": "13.3 Counter Mapping and Community Mapping",
    "text": "13.3 Counter Mapping and Community Mapping\nThere exists alternatives to the western cartographic practice which considers maps to be an objective “view from nowhere” representation of reality and employs a standardized cartesian thinking of space. These alternatives offer the opportunity to use mapmaking (Denis Wood says “cartography is dead (thank God!)” to question power and map otherwise. Countermapping refers to mapping practices that intentionally subvert or rework dominant mapping conventions in order to assert alternative spatial knowledge, often rooted in the lived experiences, struggles, and priorities of marginalized communities. Community mapping emphasizes partnerships between technically trained cartographers and local communities to support grassroots goals, such as reclaiming historical memory, resisting displacement, or asserting Indigenous land claims, while working to deconstruct power imbalances within the mapping process itself.\nUNC disOrientation\nFrom the Rock Wall\nAnti-Eviction Mapping Project\nThe Decolonial Atlas\nOrangotango\nIconoclasistas",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Making Maps</span>"
    ]
  },
  {
    "objectID": "making_maps.html#step-1-brainstorm",
    "href": "making_maps.html#step-1-brainstorm",
    "title": "13  Making Maps",
    "section": "14.1 Step 1: Brainstorm",
    "text": "14.1 Step 1: Brainstorm\nThe following factors will guide the cartographic design process:\n\nAudience: Who will be using the map? Are they experts, general public, students, or policymakers? Understanding your audience helps shape the complexity and readability of the map.\nMedium: Will the map be printed, displayed digitally, or used interactively? Different formats require different design considerations.\nPurpose: What message or information should the map convey? Is it for navigation, analysis, storytelling, or communication of patterns?",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Making Maps</span>"
    ]
  },
  {
    "objectID": "making_maps.html#step-2-decide-what-information-to-display-on-the-map",
    "href": "making_maps.html#step-2-decide-what-information-to-display-on-the-map",
    "title": "13  Making Maps",
    "section": "14.2 Step 2: Decide What Information to Display on the Map",
    "text": "14.2 Step 2: Decide What Information to Display on the Map\n\nIdentify key elements that must be included. These might be:\n\nNatural features (rivers, mountains, forests)\nHuman-made features (roads, buildings, infrastructure)\nThematic data (population density, weather patterns, election results)\n\nEach selected feature must directly contribute to the map’s message.\nAvoid excessive details—simplicity improves comprehension.\nToo much information increases cognitive load and can reduce effectiveness.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Making Maps</span>"
    ]
  },
  {
    "objectID": "making_maps.html#step-3-decide-how-to-display-information-on-the-map",
    "href": "making_maps.html#step-3-decide-how-to-display-information-on-the-map",
    "title": "13  Making Maps",
    "section": "14.3 Step 3: Decide How to Display Information on the Map",
    "text": "14.3 Step 3: Decide How to Display Information on the Map\n\nSymbols should be intuitive and align with user expectations.\nEnsure symbols are legible and not cluttered.\nReduce bottom-up processing—make it easy for users to recognize patterns without extensive thought.\nReference features (e.g., roads, rivers) should use conventional, functional, or conceptual symbols.\nThematic data should use visual variables. \n\nChoose these visual variables based on data types:\n\nCategorical Data: Use different shapes, colors, or patterns.\nOrdinal Data: Use variations in size or color intensity.\nContinuous Data: Consider graduated color schemes or proportional symbols.\n\n\nIt is often necessary to categorize continuous data. Choose a classification method that accurately represents data distribution\n\nEqual Interval: Divides range into equal-sized segments.\nQuantile: Each category contains an equal number of data points.\nNatural Breaks (Jenks): Groups similar values together.\nManual: Custom classifications for specific needs.\n\nChoose a classification method that accurately represents data distribution.\nColor should enhance comprehension, not create confusion.\n\nSequential palettes for ordered data.\nDiverging palettes to show variation from a central value.\nCategorical palettes for distinct groups.\n\nEnsure colors do not overpower or obscure key map features.\nEnsure colors are harmonious\nConsider colorblind-friendly palettes",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Making Maps</span>"
    ]
  },
  {
    "objectID": "making_maps.html#step-4-layout-the-map-and-add-map-elements",
    "href": "making_maps.html#step-4-layout-the-map-and-add-map-elements",
    "title": "13  Making Maps",
    "section": "14.4 Step 4: Layout the Map and Add Map Elements",
    "text": "14.4 Step 4: Layout the Map and Add Map Elements\n\nMost important features should stand out (figure-ground).\n\nBackground elements should be subtle to avoid distraction.\nContrast and transparency help differentiate primary and secondary elements.\n\nEnsure a proper zoom level. Key information should not be cut off or too close to the edge.\n\nCenter important features for focus.\nWhite space should be well distributed—avoid overcrowding.\n\nMap elements:\n\nScale Bar\n\nShould end on a logical, round number.\nUse a meaningful unit of measurement\n\nTitle\n\nShould be descriptive yet succinct.\nTypically placed at the top of the map.\nTitle frames/backgrounds are optional based on user preference.\n\nMetadata\n\nInclude essential details in a text box in the layout:\n\nAuthor’s name\nData source\nBasemap source (if used)\nCoordinate system\n\n\nFrameline\n\nMaintain space between the data frame and the page edge.\nThe data frame should be centered both horizontally and vertically.\nThe data frame should have a clear outline to improve focus.\n\nLegend\n\nMust have clear and descriptive labels (not just layer names).\nOnly include layers that are actively displayed.\nRound values appropriately (e.g., “5.23” → “5.2” or “5”).\nDo not include basemap names—mention basemap sources in Metadata instead.\n\nNorth Arrow\n\nNot always necessary. Use the following guidance:\n\nIf map is oriented north-up, a north arrow may be unnecessary.\nIf orientation differs from convention, include a north arrow.\n\n\nBasemap\n\nNot always necessary\nShould be purpose driven (adds, doesn’t detract, from map comprehension\nIllegible labels are common in QGIS basemaps.\nSolutions:\n\nUse unlabeled basemaps if labels are unnecessary.\nFind a readable basemap.\nUse custom labeling tools to improve label clarity.\n\n\nText and Labeling\n\nLabels should add valuable information, not clutter.\nFollow conventional text placement (e.g., rivers labeled along their curves).\nUse rule-based labeling where needed (e.g., QuickOSM for OpenStreetMap data).\nAll text should be readable on a standard laptop screen.\nAvoid fonts that are too small or overly decorative.\n\n\n\n\n\n\n\nHarley, J B. 1989. “Deconstructing the Map.” Cartographica The International Journal for Geographic Information and Geovisualization 26 (2): 1–20. https://doi.org/10.3138/e635-7827-1757-9t53.\n\n\nWood, D. 2003. “Cartography Is Dead (Thank God!).” Cartographic Perspectives, January, 4–7. https://doi.org/10.14714/CP45.497.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Making Maps</span>"
    ]
  },
  {
    "objectID": "models.html#vector-models",
    "href": "models.html#vector-models",
    "title": "5  Spatial Data Models",
    "section": "",
    "text": "Points, Intro to GIS and Spatial Analysis, CC BY-NC 4.0\n\n\n\n\n\n\nLine, Intro to GIS and Spatial Analysis, CC BY-NC 4.0\n\n\n\n\n\n\nPolygon, Intro to GIS and Spatial Analysis, CC BY-NC 4.0\n\n\n\n5.1.1 Resolution in Vector Data\nWith vector data, resolution is defined by several conditions: \n\nThe precision of the coordinates\nThe complexity of the shape (for instance, how many vertices are used to represent the feature)\nThe minimum mapping unit (MMU). This represents the smallest feature that would be included in the dataset\n\n\n\n5.1.2 Topology\nMany spatial analysis processes are dependent on topology, which expresses the spatial relationships between connecting or adjacent features. Topology is made up of three separate conditions:\n\nAdjacency – which vector features are next to each other? This is essential for tasks like neighborhood analysis or identifying shared boundaries, such as zoning districts or land parcels.\nConnectivity – which arcs (lines) connect to each other? This underlies network analysis, such as routing or tracing flows, and is determined through arc-node relationships that define from-nodes and to-nodes.\nContainment – which vector features are within other polygons? This allows GIS to determine spatial inclusion, such as identifying which buildings fall within a flood zone or which parks contain recreational facilities.\n\nWithin vector data representations the topological data model explicitly encodes topological relationships. On the other hand, the spaghetti data model does not encode topology. In this model, each feature is stored independently, as a separate set of coordinates, and spatial relationships must be inferred by comparing coordinates. \nWhile the spaghetti data model is simpler to store, there is a higher risk of topological errors. Topological errors include:\n\nUnclosed polygons (boundary does not fully loop)\nSlivers (small gaps or overlaps between polygons that should be adjacent)\nUndershoots (two lines that should meet don’t)\nOvershoots (a line extends beyond the point it should connect to)\n\nThese types of errors can seriously impact spatial analysis. Consider a routing analysis where the lines represent street segments. Undershoots and overshoots would restrict driving access on roads that should be accessible. \nQGIS uses on-the-fly topology to build temporary topological relationships for data stored in a spaghetti model. QGIS can also check for potential topology errors and set topology rules (for example, polygons must not intersect).\n\n\n5.1.3 Common Vector Data File Types\nShapefile (.shp): By far, the most common vector data file type you’ll encounter when accessing geospatial data is the Shapefile (.shp). This format, which is semi-proprietary (structured and maintained by ESRI), has become the dominant standard. This is not because it offers superior functionality, but because of ESRI’s early dominance in the GIS software market. Shapefiles are a non-topological format made up of several files, including the .shp (geometry), .shx (shape index), .dbf (attribute table), .prj (projection), and sometimes others. Despite their ubiquity, shapefiles come with serious limitations: a maximum file size of 2 GB, field names limited to 10 characters, and a maximum of 255 fields. Many believe, myself included, that Shapefile must die!\nGeoPackage (.gpkg): GeoPackage is a relatively modern, open-source format developed by the Open Geospatial Consortium (OGC). Built on SQLite, it allows multiple layers and attribute tables to exist within a single .gpkg file, streamlining data management and reducing file clutter. This structure also supports more advanced querying, similar to what’s possible in a relational database– for example, joining attribute tables, filtering by SQL expressions, or performing spatial queries within the file itself. \nGeoJSON (.geojson): GeoJSON is a lightweight, text-based format for encoding vector features using JavaScript Object Notation (JSON). It is especially popular in web mapping environments, where its structure is easily parsed by browsers and APIs. GeoJSON is limited to WGS84 coordinates. \nFile Geodatabase (.gdb):The File Geodatabase is a high-capacity, high-performance format developed by ESRI for use with ArcGIS. It stores vector data, rasters, attribute tables, topological rules, subtypes, and more in a structured folder system. This format supports large datasets (into the terabytes), long field names, and complex relationships between layers. While it’s proprietary and not natively supported by all software, it provides powerful data management and analysis capabilities within the ESRI ecosystem.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Data Models</span>"
    ]
  },
  {
    "objectID": "models.html#raster-models",
    "href": "models.html#raster-models",
    "title": "5  Spatial Data Models",
    "section": "5.2 Raster Models",
    "text": "5.2 Raster Models\nIn a raster model, real-life features are represented as an array of pixels. Instead of distinct geometries, a raster is made up of regularly spaced pixels of identical sizes, and each pixel is associated with a value. \n\n\n\nRaster, Intro to GIS and Spatial Analysis, CC BY-NC 4.0\n\n\n\n5.2.1 Resolution in Raster Data\nIn raster data, resolution refers to the size of each pixel, typically expressed in ground units (e.g., feet or meters. ). Smaller pixels mean higher resolution, capturing more detail. Most raster sources, such as satellite imagery, have fixed native resolutions determined by the sensor’s capabilities.\n\n\n\nRaster with Multiple Resolutions, Source: National Ecological Observatory Network (NEON)\n\n\n\n\n5.2.2 Topology in Raster Data\nIn raster data, topology is implied by the pixel positions, which means that it does not need to be formally encoded. Adjacency can be analyzed by identifying neighboring pixels, connectivity by analyzing whether pixels with the same value form a continuous region, and containment is often analyzed by using a mask defined by a vector data feature. \n\n\n5.2.3 Common Raster Data File Types\nGeoTIFF (.tif): GeoTIFF is the most widely used raster data format for geospatial applications. It’s a standard TIFF image that includes embedded geographic metadata (like coordinate system, bounds, and resolution), making it easy to georeference. GeoTIFFs are versatile, lossless, and widely supported across GIS platforms. They can store single-band or multi-band imagery, making them suitable for satellite images, elevation data, and classified rasters.\nNetCDF (.nc): NetCDF (Network Common Data Form) is a format commonly used for storing multidimensional scientific data, such as climate variables or oceanographic models. It supports time-series rasters, multiple dimensions (e.g., x, y, time, depth), and internal compression. NetCDFs are favored in academic and environmental modeling contexts, but can be complex to manage without specialized tools.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Data Models</span>"
    ]
  },
  {
    "objectID": "models.html#selecting-a-data-model",
    "href": "models.html#selecting-a-data-model",
    "title": "5  Spatial Data Models",
    "section": "5.3 Selecting a Data Model",
    "text": "5.3 Selecting a Data Model\nIn most cases, the type of data being collected or used will determine which data model is most appropriate. Continuous phenomena should be represented as rasters (elevation, climatic variables, etc). Discrete features should be represented with vector models (roads, buildings, property boundaries). Raster data is ideal for surface analysis, remote sensing, and modeling gradual spatial change. It supports powerful cell-by-cell calculations, but can result in large file sizes and less precise feature boundaries. Vector data is more compact and precise, and supports operations like buffering, network analysis, and spatial joins. However, vector files can be more complex to manage when dealing with continuous change or extremely large datasets.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Data Models</span>"
    ]
  },
  {
    "objectID": "models.html#coordinate-systems-and-projections",
    "href": "models.html#coordinate-systems-and-projections",
    "title": "5  Spatial Data Models",
    "section": "5.4 Coordinate Systems and Projections",
    "text": "5.4 Coordinate Systems and Projections\nTo represent the location of features, both data models rely on coordinate systems. Coordinate systems assign a numerical value to each unique location on Earth. When we import spatial data into our GIS, we use these coordinates to make sure that things are located where they should be on the map. There are two main types of coordinate systems that we use in a GIS: geographic coordinate systems (GCS) and projected coordinate systems (PCS). This incredibly informative chapter on Coordinate Systems means that I don’t have to write my own. \nCoordinate systems are defined by whoever produced the data. However, they can be reprojected, or translated to a different coordinate system, depending on your mapping needs. There are common reasons that you would want or need to reproject your data. The common reasons are detailed below:\n\nYou are trying to do spatial analysis that relies on distance. If your data is in a GCS, this means that distances are measured in angular degrees, not in a standard distance measurement (like feet, meters, etc.). Angular degrees have different distances depending on how near/far you are from the equator. For example, one degree of longitude is about 111 km at the equator, but much less near the poles. Therefore, for any analysis involving distance, area, or buffering, you should use a projected coordinate system (PCS) with linear units. \nYou have data in different coordinate systems. In general, when you are doing analysis across different coordinate systems, you should use a common coordinate system. \nLocal accuracy is important. Some projected coordinate systems are designed to minimize distortion in a specific region (e.g., a state plane zone). If you’re doing detailed work in a specific area, using a locally optimized projection will increase accuracy in measurements and reduce spatial errors.\nYour analysis would benefit from limited distortion in one (or several) spatial properties. For instance, an analysis of property parcels might need to limit area distortion to ensure that calculated parcel sizes are accurate. In this case, choosing an equal-area projection would help preserve the integrity of area measurements, even if it introduces distortion in shape or distance.\n\nQGIS allows you to reproject, as well as change coordinate systems. These are not the same thing! Reprojecting a layer means actually transforming the data from one coordinate system to another, permanently changing the coordinates stored in the file. This creates a new dataset with new X/Y values based on the target projection. You do this when you want to match coordinate systems across layers or prepare for accurate spatial analysis. Changing the coordinate system in QGIS means telling QGIS how to interpret the coordinates—without changing the data itself. This is sometimes called assigning or defining a projection. You do this when a layer was saved without projection information (or with the wrong one), and you need to clarify what system it’s in.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Data Models</span>"
    ]
  },
  {
    "objectID": "attributes.html",
    "href": "attributes.html",
    "title": "6  Attributes",
    "section": "",
    "text": "6.1 Field Types\nSpatial data generally includes two components:\nFor vector datasets, attribute information is stored in the attribute table (for instance, the .dbf in a shapefile). An attribute table is a tabular dataset, meaning it’s made up of rows and columns. Each row corresponds to a feature and every feature gets exactly one row. Each column contains information (an attribute) about that feature.\nLet’s look at an example of vector data showing pharmacies in North Carolina. In QGIS, you’d see the location of each pharmacy displayed on the map- that’s how we know where they are. But if you open the attribute table, you’ll see all the other information we have about these locations. These attributes might include the name of the pharmacy, its hours, services offered, or other descriptive details.\nFor vector data, each feature is assigned a unique ID by the GIS software. This identifier helps keep the dataset organized and is essential for tasks like joining tables, running queries, or performing spatial analysis.\nAttributes can take many forms- some are numbers, some are words, some might be dates. Understanding how this data is represented is essential for doing analysis correctly.\nEach attribute has:\nWhen you open a dataset, QGIS automatically detects the field type. Common types include:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Attributes</span>"
    ]
  },
  {
    "objectID": "attributes.html#levels-of-measurement",
    "href": "attributes.html#levels-of-measurement",
    "title": "6  Attributes",
    "section": "6.2 Levels of Measurement",
    "text": "6.2 Levels of Measurement\nThis describes how the data can be used or interpreted:\n\nNominal - Categories that can’t be ranked (e.g., pharmacy name)\nOrdinal - Categories that can be ranked (e.g., small/medium/large)\nInterval - Numbers with an arbitrary zero (e.g., temperature)\nRatio - Numbers with a true zero (e.g., number of employees)\n\nLevels of measurement and field types are connected, but they are not the same thing. Confusing them can lead to major problems when analyzing your data. The field type tells QGIS how to store and read the data (as text, numbers, dates, etc.), while the level of measurement tells you how the data should be interpreted and what kinds of analysis are appropriate. \nThe level of measurement determines what types of analysis you can do on the data. \n\nNominal- Frequencies, Mode\nOrdinal- Frequencies, Median, Mode, Ranking\nInterval- Addition, Subtraction, Mean, Median, Mode, Standard Deviation\nRatio- All arithmetic operations, mean, median, mode, percent change, normalization. \n\nThe field type controls what QGIS can do, but the level of measurement determines what you should do. Sometimes, the two don’t match, which can cause problems.\nFor example, numbers stored as text won’t behave like numbers. Even if a column looks numeric, QGIS won’t let you sort, filter, or calculate with it unless the field type is numeric. A column of income values stored as text won’t sum correctly and might sort alphabetically (e.g., 100, 1000, 200).\nOther times, the field type allows operations that don’t make sense. Categorical data is often stored as numbers- like 1 for pharmacy, 2 for clinic, 3 for hospital. QGIS will let you average or sum those values, but that’s meaningless. The numbers are labels, not quantities.\nThat’s why it’s essential to check both how the data is stored and what the data represents.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Attributes</span>"
    ]
  },
  {
    "objectID": "attributes.html#raster-attributes",
    "href": "attributes.html#raster-attributes",
    "title": "6  Attributes",
    "section": "6.3 Raster Attributes",
    "text": "6.3 Raster Attributes\nFor raster data, each pixel represents one or more values that correspond to an attribute or measurement for that location. Most raster data is single-band, meaning each pixel stores a single value representing an attribute. However, some raster datasets, particularly those from remote sensing, are multiband, which means each pixel stores multiple values corresponding to a different spectral band (e.g., red, green, blue, near-infrared).\nRaster attributes can be stored as either integers or floating-point numbers. Even rasters representing categorical data (for instance, land cover) are encoded using numeric values. In these cases, you need a legend or a value lookup table to interpret what each pixel value represents. This is another good example of categorical data being stored as numeric values, reinforcing the importance of knowing your level of measurement as well as your data type.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Attributes</span>"
    ]
  },
  {
    "objectID": "qgis.html",
    "href": "qgis.html",
    "title": "7  Working with Geographic Data in QGIS",
    "section": "",
    "text": "QGIS is a GIS software that is free and open-source. It is true that Esri products are often considered the industry standard. I’ve heard concerns from students who worry that they won’t be prepared for a GIS career if they’ve only learned in QGIS. To this, I respond that understanding GIS conceptually– being able to form spatial questions, understanding the limits of data, selecting appropriate analytical tools– is far more important than expertise in a particular software. In reality, although they can look quite different, the most commonly used GIS softwares are extremely similar. Although the initial learning curve is steep, switching from one software to another is easy. Because practicing open science is important to me, I teach in QGIS. However, anything we do in QGIS could be easily translated to ArcGIS Pro. If you want help learning how to do so, I am always available.\nWe will be using the current Long Term Release version of QGIS (QGIS 3.40 Bratislava), which can be downloaded here.\nIn the following chapters, I will provide video tutorials for some of the most common QGIS tasks. However, the best way to learn QGIS is through a lot of practice and troubleshooting, beyond what the videos prepare you for. The videos are simply meant as an aid to get you up and running in QGIS, not to solve every problem you might encounter or demonstrate every task.  There is a plethora of excellent online material for learning QGIS. For additional assistance, you can explore the following sources:\n\nA Gentle Introduction to GIS\nQGIS 3.4 User Manual\nSpatial Thoughts, Introduction to QGIS\nSpatial Thoughts, Advanced QGIS",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with Geographic Data in QGIS</span>"
    ]
  },
  {
    "objectID": "files.html",
    "href": "files.html",
    "title": "8  Managing Files",
    "section": "",
    "text": "8.1 Best Practices for File Management in this Course\nGood file management practices will make your life working with geographic data much easier. Poor file management is the number one stumbling block that I see in my GIS classes and these issues are entirely avoidable. Strong file management skills are essential not only for GIS but for any project-based work involving multiple datasets, documents, or tools- such as academic research, coding projects, group assignments, or long-term writing tasks.\nCompleting an analysis in GIS usually takes place over the course of several days, weeks, or months. We will store our GIS work in QGIS project files, which save references to layers (their file paths), map symbology, styles, coordinate reference systems, and other project settings, but not the data itself. A file path is a reference to where a file is located on your individual computer. So, in a project file, QGIS is saving where the data is stored, not the data itself. For instance, I am writing this file in a document that is stored in my “Documents” folder. For me, this file is located at this file path:\n“/Users/juliacardwell/Documents/GEOG370/geog370_text.doc”\nDisorganized folder structures increase the risk of losing data or breaking file paths in your QGIS project. Therefore, in this class, everyone will use the same folder structure. You should create a “GEOG370” folder on a location on your computer that IS NOT your “Downloads” folder. Within that folder, you will have two subfolders “Labs” and “Practicums”. Within each subfolder, you will continue to build substructures. Each QGIS project will have its own folder. It is best practice to not use spaces in folders or file names. My example GEOG370 folder structure is below:\nQGIS projects create a lot of files very quickly. Whenever you run a process in QGIS, it creates a new version of the data, which is usually displayed as a “temporary file” unless you save it specifically. Temporary files are not saved when you save the project. That means the next time you open the project, you won’t have that layer anymore. Therefore, whenever you are producing an output in QGIS that you want to keep, you must save that output in the correct location (usually your processed_data folder). If you run the same tool multiple times while troubleshooting or tweaking parameters, save the outputs with clear version labels (e.g., buffer_300m_v1.shp) and consider deleting intermediate versions you don’t need. Keeping your folders clean and organized will make it easier to know which version is “final” and reduce confusion later.\nNote on shapefiles: For a shapefile to work in QGIS, it must have all of the associated files as well (.dbf, .prj, etc.).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Managing Files</span>"
    ]
  },
  {
    "objectID": "learning_qgis.html",
    "href": "learning_qgis.html",
    "title": "9  QGIS Basics",
    "section": "",
    "text": "9.1 Starting a Project\nBefore any sort of analysis and visualization can take place, you must be extremely comfortable with creating projects, opening files, working with attributes, loading basemaps, and basic symbolization. The sample data used in this chapter can be found here.\nA project is a way to store the components of a GIS analysis in a way that when you open the project again, everything looks the same. In general, you will create a new project for each practicum/lab. When practicums/labs build on each other, you can continue using the first project you made.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>QGIS Basics</span>"
    ]
  },
  {
    "objectID": "learning_qgis.html#starting-a-project",
    "href": "learning_qgis.html#starting-a-project",
    "title": "9  QGIS Basics",
    "section": "10.1 Starting a Project",
    "text": "10.1 Starting a Project\nA project is a way to store the components of a GIS analysis in a way that when you open the project again, everything looks the same. In general, you will create a new project for each practicum/lab. When practicums/labs build on each other, you can continue using the first project you made.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>QGIS Basics</span>"
    ]
  },
  {
    "objectID": "learning_qgis.html#adding-a-basemap",
    "href": "learning_qgis.html#adding-a-basemap",
    "title": "9  QGIS Basics",
    "section": "9.2 Adding a Basemap",
    "text": "9.2 Adding a Basemap\nOnce you’ve created a project, you typically want to add a basemap to provide a geographic reference for other data you add. QGIS comes built in with two basemaps, which can be accessed in the XYZ Tiles in your Browser window.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>QGIS Basics</span>"
    ]
  },
  {
    "objectID": "learning_qgis.html#adding-raster-or-vector-data",
    "href": "learning_qgis.html#adding-raster-or-vector-data",
    "title": "9  QGIS Basics",
    "section": "9.3 Adding Raster or Vector Data",
    "text": "9.3 Adding Raster or Vector Data\nNow that you have your project set up, you are ready to add some vector and raster data. There are multiple ways to add data. The simplest way is to use the Browser panel. If you are missing your panels, watch this video. \nNote on coordinate systems: In the “Adding Data” video, you may have noticed a pop-up asking you to “Select Transformation.” This happens when the Coordinate Reference System (CRS) of the map canvas is different from the CRS of the data you’re adding. For example, in the video, the bottom right corner shows that the map canvas is using EPSG:3857 (your project might use a different one). This is because the basemap I added at the start of the project is in EPSG:3857. This is NOT reprojecting the data and it is NOT changing the CRS of the base data. We will cover that later on. In general, I just select the first transformation option.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>QGIS Basics</span>"
    ]
  },
  {
    "objectID": "learning_qgis.html#working-with-attributes",
    "href": "learning_qgis.html#working-with-attributes",
    "title": "9  QGIS Basics",
    "section": "9.4 Working with Attributes ",
    "text": "9.4 Working with Attributes \nWhen you read in vector data, one of the first things that you should do is explore the properties of the data, including looking at the data type of each of the fields and exploring the attribute table (including looking at selected features). You might also want to add a field using the field calculator (note that you must always save edits and toggle editing off when done. \nWith raster data, there is typically no separate attribute table. To explore values, you will typically use symbology or the information tab (note that the layer must be selected in the browser for the information tab to select the correct feature).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>QGIS Basics</span>"
    ]
  },
  {
    "objectID": "learning_qgis.html#basic-symbolization",
    "href": "learning_qgis.html#basic-symbolization",
    "title": "9  QGIS Basics",
    "section": "9.5 Basic Symbolization",
    "text": "9.5 Basic Symbolization\nChances are, the symbolization that is automatically applied when you add your data into QGIS is not going to be sufficient. Symbology choices are some of the most important choices that you will make when creating maps. There are many symbology choices available in QGIS. Explore these resources for more information:\n\nLesson: Changing Raster Symbology\nLesson: Symbology\n\nHere are the basics of changing vector and raster symbology",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>QGIS Basics</span>"
    ]
  },
  {
    "objectID": "learning_qgis.html#adding-tabular-data-and-executing-table-joins",
    "href": "learning_qgis.html#adding-tabular-data-and-executing-table-joins",
    "title": "9  QGIS Basics",
    "section": "9.6 Adding Tabular Data and Executing Table Joins",
    "text": "9.6 Adding Tabular Data and Executing Table Joins\nAs discussed in Chapter 6, sometimes geospatial data comes in a tabular format.You can easily add tabular data that has a lat, lon fields by using the Data Source Manager. \nFinally, table joins are an absolutely essential pre-processing step for many spatial analyses. A table join involves joining tabular data and spatial data based on a matching key. For this to work in QGIS, it is required that the matching keys are exactly the same (which is often a problem) and are set as the same data type in QGIS.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>QGIS Basics</span>"
    ]
  },
  {
    "objectID": "spatial_analysis.html",
    "href": "spatial_analysis.html",
    "title": "10  Spatial Analysis",
    "section": "",
    "text": "Spatial analysis refers to the set of methods and techniques used to answer spatial questions- those that involve the location, arrangement, and relationships of objects or phenomena in space (Chapter 1). It is the process by which we interpret spatial patterns, model spatial processes, and understand spatial relationships. With the growth of GIScience, a distinct spatial analysis toolkit has emerged tha recognizes that “spatial is special.” This idea highlights that spatial data offers unique analytical potential that differs fundamentally from non-spatial data, due to properties like spatial autocorrelation, spatial heterogeneity, and the importance of scale and proximity in shaping outcomes (Chapter 3).\nSpatial analysis encompasses a wide variety of techniques. Measurement is the most basic form, allowing users to calculate straight-line (Euclidean) distances between points or along paths. Distance often serves as a foundational variable in understanding interactions between people and places. Topological analysis focuses on spatial relationships such as adjacency, connectivity, and containment. Spatial overlays and geoprocessing techniques like clipping, union, or intersect fall under this category and are especially important for modeling networks or defining shared areas. Network and location analysis investigates flows through networks (such as roads, pipelines, or transit systems) and is often used for routing, service area delineation, and accessibility studies.\nSurface analysis is used for working with continuous phenomena such as elevation, temperature, or pollution. These techniques include raster-based filtering, interpolation, and terrain modeling. Finally, statistical spatial analysis involves quantifying spatial relationships, testing spatial patterns, or modeling spatially structured data. Spatial statistics help evaluate clustering, spatial autocorrelation, and relationships between attributes and geography. All of these analytical approaches are grounded in spatial logic and rely on a solid understanding of data structure, measurement, and the inherent limitations of geographic data.\nPracticing critical GIS offers us opportunities to critically analyze the questions that we ask, the data we select, and the methods that we use.\nRead:\n\nShelton, Taylor. “The urban geographical imagination in the age of Big Data.” Big Data & Society 4, no. 1 (2017): 2053951716665129.\nGoodchild, M. F., & Janelle, D. G. (2010). Toward critical spatial thinking in the social sciences and humanities. GeoJournal, 75, 3-13.\nBurg, Marieka Brouwer. “It must be right, GIS told me so! Questioning the infallibility of GIS as a methodological tool.” Journal of Archaeological Science 84 (2017): 115-120.\nBrunsdon, Chris, and Alexis Comber. “Opening practice: supporting reproducibility and critical spatial data science.” Journal of Geographical Systems 23, no. 4 (2021): 477-496.\nGoodchild, Michael F. “The validity and usefulness of laws in geographic information science and geography.” Annals of the Association of American Geographers 94, no. 2 (2004): 300-303.\nWhat Does a Critical Data Studies Look Like and Why Do We Care",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Spatial Analysis</span>"
    ]
  },
  {
    "objectID": "doing_spatial_analysis.html",
    "href": "doing_spatial_analysis.html",
    "title": "11  Doing Spatial Analysis in QGIS",
    "section": "",
    "text": "11.1 Research Question 1\nThis chapter introduces common spatial analysis tools and demonstrates how to use them in QGIS. Spatial questions often require chaining together multiple spatial operations, rather than relying on a single tool. Throughout this course, we will focus on designing spatial workflows that combine these tools effectively to answer geographic questions. Remember that when using most of these spatial analysis tools, your data should be in a projected coordinate system to ensure accurate distance and area calculations.\nThis chapter will explore the use of vector and raster geoprocessing tools to explore three spatial questions. In addition, it will ask you to critically examine the questions, methods, and data in a critical GIS style.\nWhere is the intersection between vulnerable populations and existing permitted facilities that require a Major Air) permit in North Carolina?",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Doing Spatial Analysis in QGIS</span>"
    ]
  },
  {
    "objectID": "doing_spatial_analysis.html#research-question-1",
    "href": "doing_spatial_analysis.html#research-question-1",
    "title": "11  Doing Spatial Analysis in QGIS",
    "section": "",
    "text": "11.1.1 Download Data\n\n2010 Census Block Group Median Household Income (from 2013 American Community Survey)\nCurrent (June 2025) Major Air permits from EPA Geospatial Data\n\n\n\n11.1.2 Adding Data\nWe can add tabular data to QGIS as long as we can execute a table join (so it has a matching key with a geographic data file) or the tabular file includes coordinates. We’ll first add our air permit data. You must know the coordinate system of the data (which should be in the metadata) to add it correctly. We’ll also add our processed census data, which we table joined in a previous exercise. \n\n\n11.1.3 Select by Attribute\nFirst, we will want to filter the census block group data to include only block groups that meet our “vulnerable population” classification (median household income &lt; 4500). We will do this by selecting by attribute, which is an example of querying. \n\n\n11.1.4 Reproject\nAs you may have noticed, the tabular dataset representing locations with major air quality permits is in a Geographic Coordinate System, not a projected one. Given that we are going to be doing distance-based analysis, we must reproject that data. We typically want to make sure that all our datasets are in the same projection, so we will reproject the data to match the projection of our census block group data (EPSG:2264). \n\n\n11.1.5 Buffer\nNow we want to identify areas within 1 mile of existing permitted facilities by buffering our facility dataset (which is currently points)\n\n\n11.1.6 Intersect\nTo find the intersection between vulnerable populations and areas proximate to high polluting facilities, we will use the intersect tool. Intersects retain the attributes of both of the layers, whereas a clip, which would have visually the same output, retains the attributes only of the input layer, not the overlay layer. \n\n\n11.1.7 Critical Questions to Ask:\n\nWhat assumptions are embedded in defining “vulnerable populations” based solely on median household income?\nWhy do we choose a 1-mile buffer, and what are the implications of this distance?\nWhat is the source of the EPA permit data, and what might be missing?\nThis analysis uses 2010 block group data from the 2013 American Community Survey. What are the risks of using outdated demographic data for present-day decision-making?\nWhat are the implications of using the census block group as the unit of analysis?",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Doing Spatial Analysis in QGIS</span>"
    ]
  },
  {
    "objectID": "doing_spatial_analysis.html#research-question-2",
    "href": "doing_spatial_analysis.html#research-question-2",
    "title": "11  Doing Spatial Analysis in QGIS",
    "section": "11.2 Research Question 2",
    "text": "11.2 Research Question 2\nHow many addresses are served by each park in Chapel Hill? \n\n11.2.1 Download Data\n\nAddress points from Orange County GIS\nParks from Chapel Hill Open Data\nChapel Hill boundaries from Chapel Hill Open Data\n\n\n\n11.2.2 Reproject\nAs always, we want to make sure that our data shares the same coordinate system before beginning spatial analysis. You should notice that the address and Chapel Hill boundary datasets are in EPSG:2264 and the parks dataset is in EPSG:3857. These are both projected coordinate systems, however EPSG:2264 is a local projection built for North Carolina. EPSG:3857 is a more globally focused projection. Since EPSG:2264 would be slightly more accurate for North Carolina, reproject the parks to EPSG:2264\n\n\n11.2.3 Clip\nWe now want to clip the address dataset so that we just have addresses within the Chapel Hill boundary. A clip will just retain the attributes of the address dataset and will not include the attributes of the boundary dataset. \n\n\n11.2.4 Calculate Service Area\nFollow these instructions to download the ORS plugin. Then calculate 10 minute isochrones from each park. Note that when you save the data (which is produced in EPSG:2264) you can set the PCS of the output so it reprojects when it saves. \n\n\n11.2.5 Spatial Join\nThere is not a common “key” field between the service areas and our address data. Instead, the commonality between these two datasets is their spatial location. Therefore, to join these two datasets, we will use a spatial join. In this case, we will do a “join attributes by location (summary)” since we want to summarize the number of address points within each service area polygon. If we were interested in assigning each address point the name of the park whose service area it falls within we would use a regular spatial join (called “Join attributes by location” in QGIS). This type of join appends the attributes of one layer to another based on spatial relationships like intersection, containment, or proximity, but does not summarize counts or statistics.\n\n\n11.2.6 Critical Questions to Ask:\n\nWhat assumptions are we making when we define ‘served’ as being within a 10-minute isochrone from a park?\nHow does the ORS plugin model pedestrian access, and what does it ignore?\nAre addresses a good stand-in for people?\nWhat does “serving” an address mean, physically, socially, or politically?\nDoes a 10-minute walk on a map mean that it’s safe, comfortable, or desirable to walk there in real life?\nWhat would it take to integrate community knowledge into this analysis?",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Doing Spatial Analysis in QGIS</span>"
    ]
  },
  {
    "objectID": "doing_spatial_analysis.html#research-question-3",
    "href": "doing_spatial_analysis.html#research-question-3",
    "title": "11  Doing Spatial Analysis in QGIS",
    "section": "11.3 Research Question 3",
    "text": "11.3 Research Question 3\nWhich areas of Buncombe County are most vulnerable to wildfire? \n\n11.3.1 Download Data\n\n2023 National Land Cover Database MLRC\nBuncombe County DEM from North Carolina Spatial Data Download\nBuncombe County Zip Codes from Buncombe County Open Data\n\n\n\n11.3.2 Calculate Slope\nUse the Buncombe County DEM to calculate slope using the slope tool. The output will be a continuous raster showing degrees of steepness. Areas with steeper slopes are generally more vulnerable to wildfire spread.\nThe output is in a Projected Coordinate System. However, we will then reproject the slope raster to WGS 84 (EPSG:4326) to match the coordinate system of the NLCD dataset. This may seem like a weird choice (reprojecting data in a projected coordinate system into a geographic coordinate system). However, this approach avoids reprojecting the NLCD data, which is important because the NLCD data is a categorical raster. Reprojecting categorical rasters introduces a higher risk of distortion due to resampling. To preserve the integrity of the land cover classes, we keep the NLCD in its original form and instead reproject the slope raster, which is continuous data and more resilient to interpolation.\n\n11.3.2.1 Reclassify Rasters\nWe will reclassify both the slope and land cover rasters onto a common risk scale from 1 (low risk) to 5 (high risk).\n\nFor slope, use thresholds based on terrain steepness (e.g., 0–5 degrees = 1, 35–65 = 5).\nFor NLCD, reclassify land cover values based on their flammability (e.g., forest = 5, developed = 1–2).\n\nUse the r.reclass tool and copy-paste the provided reclass rules for each raster. The output of each will be a categorical risk raster.\n\n\n11.3.2.2 Slope\n\n\n\n\n\n\n\n\n\nFrom (degrees)\nTo (degrees)\nOutput (Risk Score)\nSlope Category\n\n\n0\n5\n1\nVery Low Slope\n\n\n5\n15\n2\nLow Slope\n\n\n15\n25\n3\nModerate Slope\n\n\n25\n35\n4\nHigh Slope\n\n\n35\n65\n5\nVery High Slope\n\n\n\nThis is what to paste in the “Reclass rules text”:\n0 thru 5 = 1\n5 thru 15 = 2\n15 thru 25 = 3\n25 thru 35 = 4\n35 thru 65 = 5\n* = NULL\n\n\n11.3.2.3 NLCD\n\n\n\nValue\nOutput (Risk Score)\nNLCD Class\n\n\n11\n1\nOpen Water\n\n\n21\n2\nDeveloped, Open Space\n\n\n22\n2\nDeveloped, Low Intensity\n\n\n23\n2\nDeveloped, Medium Intensity\n\n\n24\n1\nDeveloped, High Intensity\n\n\n31\n3\nBarren Land\n\n\n41\n5\nDeciduous Forest\n\n\n42\n5\nEvergreen Forest\n\n\n43\n5\nMixed Forest\n\n\n52\n4\nShrub/Scrub\n\n\n71\n4\nGrassland/Herbaceous\n\n\n81\n3\nPasture/Hay\n\n\n82\n2\nCultivated Crops\n\n\n90\n2\nWoody Wetlands\n\n\n95\n2\nEmergent Herbaceous Wetlands\n\n\n\nThis is what to paste in the “Reclass rules text” \n11 = 1\n21 = 2\n22 = 2\n23 = 2\n24 = 1\n31 = 3\n41 = 5\n42 = 5\n43 = 5\n52 = 4\n71 = 4\n81 = 3\n82 = 2\n90 = 2\n95 = 2\n* = NULL\n\n\n\n11.3.3 Raster Math\nNow we combine the two reclassified rasters using the Raster Calculator. This step adds the slope and land cover risk scores, producing a composite vulnerability raster that reflects both terrain and vegetation.This technique is an example of a Multi-Criteria Overlay Analysis (MCOA) which is  a method used to combine multiple spatial layers, each representing a different factor contributing to a phenomenon (in this case, wildfire risk). Each layer is first standardized (here, using a 1–5 risk scale), then combined to create a single index or score. By summing the slope and land cover risk scores, we are weighting them equally (50% each). This assumes that slope and vegetation are equally important in determining wildfire vulnerability. In more complex analyses, different layers might be given different weights to reflect their relative importance.\nWhen performing raster math, QGIS will automatically resample rasters on the fly so that their cell alignments and resolutions match. However, this may introduce interpolation artifacts. If high precision is required, you should explicitly resample the input rasters beforehand using the “Resample” tool. Multiple resampling methods exist (e.g., nearest neighbor, bilinear, cubic), and the appropriate one depends on the input data.\n\n\n11.3.4 Zonal Statistics\nTo summarize vulnerability by administrative unit, we use zonal statistics (which summarizes raster values based on vector boundaries). Input the ZIP code polygons and the combined wildfire risk raster. Calculate the mean value for each ZIP code. This gives an average vulnerability score (ranging roughly from 2 to 10) that reflects the average risk across each ZIP code.\n\n\n11.3.5 Critical Questions to Ask:\n\nHow does the choice of administrative unit (ZIP codes) shape our understanding of vulnerability?\nWhat assumptions are embedded in the risk classification thresholds for slope and land cover?\nWhat important variables are missing from this model of wildfire vulnerability?\nWhat are the limitations of using a strictly biophysical model for a hazard with complex social consequences?",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Doing Spatial Analysis in QGIS</span>"
    ]
  },
  {
    "objectID": "other_tools.html",
    "href": "other_tools.html",
    "title": "12  Analysis Tools",
    "section": "",
    "text": "12.1 Vector Analysis Tools\nThe three research questions in the last chapter introduced you to some of the most commonly used vector and raster analysis tools available in QGIS. Below, you will find a more detailed list of tools.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Analysis Tools</span>"
    ]
  },
  {
    "objectID": "other_tools.html#vector-analysis-tools",
    "href": "other_tools.html#vector-analysis-tools",
    "title": "12  Analysis Tools",
    "section": "",
    "text": "12.1.1 Buffer\nA buffer creates a zone around a selected feature (point, line, or polygon) at a specified distance. \nExample: You are examining flood risk around streams (line vectors). Your first step may be to determine a reasonable area outside of the stream that you would want to examine for risk. Therefore, you might buffer the stream lines 150ft. \n\n\n12.1.2 Variable Buffer\nA variable buffer applies different distances to features based on a specific attribute in the dataset. Instead of a single distance for all features, each feature’s buffer size is determined by an existing data field.\nExample: You are looking at noise pollution from roadways. High volume roads (such as highways) may have impacts at a further distance than low volume roads (like residential roads). You may choose to buffer high volume roads .5 miles and low volume roads .25 miles. \n\n\n12.1.3 Clip\nThe clip tool extracts features from one dataset that fall within the boundary of another. The output contains only the features within the defined boundary while maintaining their original attributes.\nExample: You have a dataset representing schools in North Carolina, but are only interested in schools in Orange County, so you clip the school dataset by a polygon representing Orange County boundaries\n\n\n12.1.4 Merge \nThe merge tool combines multiple layers of the same feature type (points, lines, or polygons) into a single dataset without modifying geometries. Attributes from all input layers are preserved in the output dataset. If a field exists in one layer but not in another, QGIS fills the missing values with NULLs.\nExample: You have a parcel dataset from Orange County and one from Alamance County and would like to analyze the data together. \n\n\n12.1.5 Dissolve\nDissolve merges adjacent polygons that share a common attribute into a single, larger feature. \nExample: You have a land cover dataset with a more detailed primary land cover and a simpler secondary land cover. You want to create polygons just based on the secondary land cover\n\n\n12.1.6 Intersect\nThis tool extracts the portions of features from the input layer that overlap features in the overlay layer. Features in the intersection layer are assigned the attributes of the overlapping features from both the input and overlay layers.\nExample: You have a dataset of flood zones and another of residential parcels. You use the intersect tool to identify and extract only the parts of residential parcels that fall within flood zones, combining the attributes from both datasets in the output.\n\n\n12.1.7 Union\nUnion combines two polygon layers while preserving all features and attributes from both. Unlike intersection, it keeps all areas from both input layers. This tool checks overlaps between features within the input layer and creates separate features for overlapping and non-overlapping parts. The area of overlap will create as many identical overlapping features as there are features that participate in that overlap.\nExample: You are analyzing both zoning areas and historic district boundaries. You use the union tool to combine the two polygon layers so that each resulting polygon shows both its zoning category and whether or not it is in a historic district.\n\n\n12.1.8 Difference\nThe difference tool subtracts one layer from another, keeping only the portions of the input layer that do not overlap with the second layer. The output layer contains only the unique portions of the input dataset.\nExample: You want to identify areas within a park boundary that are not occupied by water features. You use the difference tool to subtract the water feature polygons from the park polygon.\n\n\n12.1.9 Symmetrical Difference\nSimilar to the difference tool, this process removes areas of overlap but keeps the unique portions of both input layers. The resulting dataset excludes any areas that intersect, leaving only the areas that are exclusive to each input. \nExample: You want to identify areas where two proposed zoning plans disagree. You use the symmetrical difference tool to remove the overlapping areas and keep only the zones that are unique to each plan.\n\n\n12.1.10 Spatial Join\nA spatial join transfers attributes from one dataset to another based on spatial relationships. Unlike a traditional table join, which relies on matching attribute values, a spatial join links records based on location.\nExample: You have a layer of apartment buildings and a layer of census tracts with income data. You use spatial join to assign each apartment building the average income of the census tract it falls within.\n\n\n12.1.11 Points-in-Polygon (Join Attributes by Location - Summary)\nThis tool counts or summarizes point data within each polygon feature. It is often used for aggregating information. The output layer retains polygon features with new statistical values.\nExample: You want to count the number of businesses (points) within each zip code. \n\n\n12.1.12 Table Join\nA table join connects attribute data from different sources using a common field, such as an ID number. This process does not alter geometries but enriches the dataset with additional information. \nExample: You have a zip code boundary dataset and health information (tabular) at the zip code level. \n\n\n12.1.13 Voronoi Diagram\nThis tool creates polygons around a set of points so that each polygon contains all locations closest to its corresponding point. The resulting polygons divide space based on distance to the nearest input point.\nExample: You are analyzing access to hospitals across a region. You create a Voronoi diagram around hospital locations to define the area closest to each hospital, helping visualize their service areas.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Analysis Tools</span>"
    ]
  },
  {
    "objectID": "other_tools.html#raster-tools",
    "href": "other_tools.html#raster-tools",
    "title": "12  Analysis Tools",
    "section": "12.2 Raster Tools",
    "text": "12.2 Raster Tools\n\n12.2.1 Raster Math\nThis process performs mathematical operations on raster data to modify or analyze values. \nExample: You subtract a temperature raster from a historical average raster to map recent anomalies in surface temperature.\n\n\n12.2.2 Extract by Mask\nThis tool clips a raster dataset using a vector boundary, keeping only the raster cells within the specified area. The output retains the original raster values but is spatially confined to the selected area.\nExample: You clip a land cover raster to the boundary of a national park to analyze vegetation types only within the protected area.\n\n\n12.2.3 Sample Raster Values\nThis tool extracts pixel values from a raster dataset at specific locations, typically defined by point features. \nExample: You extract elevation values at wildlife observation points to study habitat preferences by elevation.\n\n\n12.2.4 Reclassify Raster\nThis process assigns new values to raster cells based on classification rules\nExample: You reclassify a land cover raster so that all forest types are grouped under a single “forest” category for simplified analysis.\n\n\n12.2.5 Hillshade\nHillshade generates a shaded relief map based on elevation, simulating how light and shadow affect terrain. \nExample: You generate a hillshade from a DEM to visually emphasize terrain for a printed topographic map.\n\n\n12.2.6 Slope and Aspect\nThese tools derive terrain characteristics from elevation data. The slope tool calculates the steepness of the terrain, while the aspect tool determines the direction a surface faces. \nExample: You calculate slope and aspect to determine suitable areas for solar panel installation, avoiding steep and north-facing slopes.\n\n\n12.2.7 Contour Lines\nThis tool converts elevation raster data into contour lines representing constant elevation values. The output is a vector dataset of elevation curves.\nExample: You create contour lines from elevation data to show terrain features on a hiking trail map.\n\n\n12.2.8 Georeferencing\nGeoreferencing aligns raster images to real-world coordinates by assigning control points to known locations. \nExample: You georeference a scanned historical map of Carrboro so that you can use it as a basemap for comparison with current data.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Analysis Tools</span>"
    ]
  },
  {
    "objectID": "other_tools.html#selection-description-and-summary-tools",
    "href": "other_tools.html#selection-description-and-summary-tools",
    "title": "12  Analysis Tools",
    "section": "12.3 Selection, Description, and Summary Tools",
    "text": "12.3 Selection, Description, and Summary Tools\n\n12.3.1 Select by Attribute\nThis tool filters data based on attribute values using SQL-like expressions. \nExample: You select all parcels where the zoning code is “R-10” to identify areas designated for medium-density residential development.\n\n\n12.3.2 Select by Location\nThis tool selects features based on their spatial relationship to another dataset\nExample: You select all schools that fall within 500 meters of a major road to analyze noise exposure risks.\n\n\n12.3.3 Zonal Statistics\nThis tool calculates statistical values (sum, mean, max, etc.) for raster data within defined polygon boundaries. The output adds fields to a new polygon output with statistical values from the raster\nExample: You calculate the average elevation within each watershed to assess how terrain might influence streamflow patterns.\n\n\n12.3.4 Field Calculator\nThis tool allows users to create or modify attribute fields using formulas and expressions. \nExample: You create a new field that multiplies area by a tax rate to estimate potential revenue from each land parcel.\n\n\n12.3.5 Aggregate Statistics\nThis tool computes summary statistics for grouped attributes within a dataset. \nExample: You calculate the mean household income for each county by grouping census block data by county boundaries.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Analysis Tools</span>"
    ]
  },
  {
    "objectID": "other_tools.html#other-tools",
    "href": "other_tools.html#other-tools",
    "title": "12  Analysis Tools",
    "section": "12.4 Other Tools",
    "text": "12.4 Other Tools\n\n12.4.1 Batch Processing\nThis tool automates repetitive spatial operations by running them on multiple datasets simultaneously. \nExample: You batch convert dozens of shapefiles to GeoPackages to standardize your project’s data format.\n\n\n12.4.2 Model Designer\nThe model designer allows users to create workflows that chain multiple QGIS processes into a single automated operation. Once designed, models can be reused for similar analyses.\nExample: You build a model that automatically clips, reprojects, and joins land use data for each new municipality added to your project.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Analysis Tools</span>"
    ]
  },
  {
    "objectID": "data.html#where-does-geographic-data-come-from",
    "href": "data.html#where-does-geographic-data-come-from",
    "title": "4  What is Geographic Data?",
    "section": "4.2 Where does geographic data come from?",
    "text": "4.2 Where does geographic data come from?\nHistorically, geospatial data was collected almost exclusively by state institutions, militaries, and professional surveyors. These data sources were considered “authoritative” because they relied on credentialed experts, standardized tools, and formal methodologies to achieve a high degree of accuracy. Early data collection involved resource-intensive methods like land surveying (using total stations and reference points), aerial photography for photogrammetry, remote sensing, and field data collection during censuses. The tools were expensive, slow, and required specialized training, but they produced high-quality data with thorough documentation (metadata). At the same time, they necessarily represented and re-created the priorities of those funding its acquisition. \nSome of the common sources of “authoritative” spatial data include: \n\nUS Census Bureau\n\nPopulation counts and demographics (e.g., race, age, income)\nHousing and economic data\nGeographic boundaries (e.g., census tracts, block groups, ZIP code tabulation areas)\n\nUS Geological Survey (USGS) \n\nTopographic maps\nElevation and terrain (e.g., DEMs)\nLand cover and land use (e.g., NLCD)\nHydrography (rivers, lakes, watersheds)\nGeologic and seismic data\n\nNASA\n\nWeather and climate data\nCoastal and marine mapping (e.g., nautical charts, sea surface temperature)\nFlood zones and storm surge models\nFisheries and oceanographic data\n\nState and Local Governments\n\nParcel and zoning data\nTransportation networks (roads, transit routes)\nUtilities and infrastructure (e.g., water lines, sewer systems)\nLand use plans and municipal boundaries\n\nEPA\n\nAir and water quality data\nEnvironmental justice mapping (e.g., EJScreen)\nRegulated facility locations",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#how-is-geographic-data-collected",
    "href": "data.html#how-is-geographic-data-collected",
    "title": "4  What is Geographic Data?",
    "section": "4.3 How is geographic data collected?",
    "text": "4.3 How is geographic data collected?\n\n4.3.1 Remote sensing\nUses satellites or aircraft to capture reflected or emitted energy from the Earth’s surface. Because different surfaces reflect energy at different wavelengths, this method can be used to identify and classify surfaces on earth.\n\n\n\nRemote Sensing, Credit: Arkarjun, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\n\n4.3.2 Land Surveys\nSurveying is a method of collecting highly accurate location data by measuring distances and angles between known points on the ground. Surveyors often use tools like total stations, which send laser signals to a reflective prism to calculate distance and direction, or survey-grade GPS units that use satellite signals with corrections from nearby base stations to achieve centimeter-level accuracy. By combining these measurements with known reference points (control points), surveyors can calculate the precise coordinates of new locations. \n\n\n\nLand Survey Equipment, Credit: Bureau of Land Management Oregon and Washington, Public domain, via Wikimedia Commons\n\n\n\n\n4.3.3 Sensors\nSensors are placed in fixed locations and are typically used to collect environmental data, such as air pollution, rainfall, or noise levels, over short or extended periods of time. For instance, the national ASOS/AWOS network consists of over 900 stations across the US collecting weather data for over 30 years. \n\n\n\nAWOS Station, Credit: Famartin, CC BY-SA 3.0, via Wikimedia Commons\n\n\n\n\n4.3.4 GPS/GNSS\nGPS works through trilateration, which determines location by measuring distances from multiple satellites. Each satellite sends a signal with the time it was sent which allows GPS devices on the ground to calculate how far the satellite is from the device location. With signals from at least four satellites, the GPS receiver can determine your exact position on Earth (latitude, longitude, and elevation). GPS uses only the US satellite network, GNSS uses the global network.\n\n\n\nTrilateration, Credit: Javiersanp, CC BY-SA 4.0, via Wikimedia Commons\n\n\n\n\n4.3.5 Aerial Photography\nImages captured from planes or drones are used to document the Earth’s surface\n\n\n\nImagery Collected after Hurricane Helene, Credit: NOAA\n\n\n\n\n4.3.6 LiDAR (Light Detection and Ranging)\nLiDAR uses rapid laser pulses from aircraft or drones to measure the distance to the ground. By calculating how long it takes the light to bounce back, LiDAR can produce highly detailed 3D models. \n\n\n4.3.7 Photogrammetry\nPhotogrammetry involves taking many overlapping images of the same area, usually from drones or aircraft, and using software to extract depth, shape, and spatial relationships. It’s commonly used for creating orthophotos, elevation models, and 3D reconstructions.\n\n\n\nPhotogrammetry, Credit: NELAC , CC BY-SA 4.0, via Wikimedia Commons\n\n\n\n\n4.3.8 Census and Surveys\nThese methods gather demographic, social, and economic data directly from people through questionnaires, interviews, or field observations. The U.S. Census, for example, collects data on population, housing, and income and ties this information to geographic areas for mapping and policy use.\n\n\n4.3.9 Could Be Spatial Data\nMany data sources contain locational information, even if geography is not their primary focus. For example, health records often include patient zip codes, census tracts, or home addresses; tax documents may list property locations or mailing addresses; school enrollment data might be tied to district boundaries or bus routes. While these datasets are not explicitly spatial in origin, they become spatial when analyzed through the lens of geography.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "data.html#new-sources-of-geographic-data",
    "href": "data.html#new-sources-of-geographic-data",
    "title": "4  What is Geographic Data?",
    "section": "4.4 New Sources of Geographic Data",
    "text": "4.4 New Sources of Geographic Data\nCollecting geospatial data is now easier than ever. Almost every smartphone has built-in GPS/GNSS. Instead of the ability to collect geospatial data being relatively restricted, it is now possible for nearly anyone to record geographic data. In addition, the rise of online mapping tools like Google Earth has also made geospatial technologies more accessible to the public. As a result, geospatial data collection is no longer confined to experts or specialized equipment, leading to an explosion in the amount of data being generated. These crowdsourced and citizen-generated datasets are now used to support everything from disaster response to urban planning.\nSome well-known examples include:\n\nOpenStreetMap: A free, crowdsourced map of the world built by millions of contributors, widely used in humanitarian efforts and mapping underserved areas.\nMapillary: A platform where users upload street-level imagery to support navigation, urban development, and computer vision training.\neBird: A citizen science project where birdwatchers record sightings, contributing to biodiversity monitoring and conservation.\niNaturalist: A platform where people document observations of plants and animals, helping scientists track species distribution and ecological change.\n\nCrowdsourced or community-collected geospatial data has become an increasingly important way to capture information that is intentionally or unintentionally missed by “authoritative” sources. These grassroots efforts often seek to fill data gaps that disproportionately affect marginalized communities. However, the rise of crowdsourced data has also created tension between official and unofficial sources, which has raised questions about what kinds of data are considered legitimate and who is qualified to collect them. \n\n4.4.1 Case Study\nLouisiana Bans Community Air Quality Data\nIn Louisiana, particularly in the heavily industrialized region known as “Cancer Alley”, residents have been raising concerns about high levels of pollution near industrial facilities. A lack of “authoritative” air pollution data in the area (due to the EPA’s sparse and unevenly distributed monitoring network) meant that community members were unable to validate their concerns. In response, community members began using low-cost air quality sensors to collect their own data. \nHowever, in May 2023, Louisiana passed legislation banning the use of community-collected air quality data in legal or regulatory processes. Lawmakers justified the ban by citing concerns about the accuracy, calibration, and scientific rigor of the sensors used. This decision effectively invalidated grassroots efforts to document environmental health risks and reinforced institutional control over which data “counts.” It also revealed deeper tensions around participatory data, raising questions about who defines data quality, how metadata and standards are used to include or exclude information.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What is Geographic Data?</span>"
    ]
  },
  {
    "objectID": "attributes.html#field-types",
    "href": "attributes.html#field-types",
    "title": "6  Attributes",
    "section": "",
    "text": "Boolean – Yes/No, True/False, 1/0, etc.\nWhole Number (Integer)\nWhole Number (Integer - 64 bit)\nDecimal Number – Double precision (i.e., numbers with decimals)\nDate\nTime\nDate and Time\nText",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Attributes</span>"
    ]
  },
  {
    "objectID": "files.html#best-practices-for-file-management-in-this-course",
    "href": "files.html#best-practices-for-file-management-in-this-course",
    "title": "8  Managing Files",
    "section": "",
    "text": "GEOG370 File Structure Example",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Managing Files</span>"
    ]
  },
  {
    "objectID": "files.html#enterprise-gis-and-the-limits-of-file-based-systems",
    "href": "files.html#enterprise-gis-and-the-limits-of-file-based-systems",
    "title": "8  Managing Files",
    "section": "8.2 Enterprise GIS and the Limits of File-Based Systems",
    "text": "8.2 Enterprise GIS and the Limits of File-Based Systems\nThroughout this course, we will work with shapefiles and other local file types to store and analyze spatial data on our individual computers. These are examples of file-based GIS, where each dataset exists as a separate file on your computer. While this works well for small, individual projects, it becomes unmanageable at larger scales. File-based systems struggle with version control, performance, and collaboration. For instance, only one user can edit a shapefile at a time, and there is no built-in way to track changes or prevent accidental edits. \nIn contrast, enterprise GIS refers to systems where spatial data is stored in centralized relational databases, accessed and managed through networked environments. Working in a professional GIS environment generally requires working in an enterprise, rather than file-based, system. In an enterprise system, instead of opening static files, users query the database to retrieve just the data they need which allows for faster, more secure, and collaborative workflows. These relational databases are accessed and queried using SQL (Structured Query Language). With spatial SQL (enabled by platforms like PostGIS or Oracle Spatial), users can run spatial queries (such as finding intersections, measuring distances, or calculating areas) directly on the database. While full enterprise systems may be beyond the scope of this course, tools like GeoPackage offer many of the same benefits in a more accessible format. GeoPackages support SQL-based analysis, spatial indexing, and multi-layer storage, and it is open-source!",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Managing Files</span>"
    ]
  },
  {
    "objectID": "making_maps.html#cartographic-design-guide",
    "href": "making_maps.html#cartographic-design-guide",
    "title": "13  Making Maps",
    "section": "13.4 Cartographic Design Guide",
    "text": "13.4 Cartographic Design Guide\n\n13.4.1 Step 1: Brainstorm\nThe following factors will guide the cartographic design process:\n\nAudience: Who will be using the map? Are they experts, general public, students, or policymakers? Understanding your audience helps shape the complexity and readability of the map.\nMedium: Will the map be printed, displayed digitally, or used interactively? Different formats require different design considerations.\nPurpose: What message or information should the map convey? Is it for navigation, analysis, storytelling, or communication of patterns?\n\n\n\n13.4.2 Step 2: Decide What Information to Display on the Map\n\nIdentify key elements that must be included. These might be:\n\nNatural features (rivers, mountains, forests)\nHuman-made features (roads, buildings, infrastructure)\nThematic data (population density, weather patterns, election results)\n\nEach selected feature must directly contribute to the map’s message.\nAvoid excessive details—simplicity improves comprehension.\nToo much information increases cognitive load and can reduce effectiveness.\n\n\n\n13.4.3 Step 3: Decide How to Display Information on the Map\n\nSymbols should be intuitive and align with user expectations.\nEnsure symbols are legible and not cluttered.\nReduce bottom-up processing—make it easy for users to recognize patterns without extensive thought.\nReference features (e.g., roads, rivers) should use conventional, functional, or conceptual symbols.\nThematic data should use visual variables. \n\nChoose these visual variables based on data types:\n\nCategorical Data: Use different shapes, colors, or patterns.\nOrdinal Data: Use variations in size or color intensity.\nContinuous Data: Consider graduated color schemes or proportional symbols.\n\n\nIt is often necessary to categorize continuous data. Choose a classification method that accurately represents data distribution\n\nEqual Interval: Divides range into equal-sized segments.\nQuantile: Each category contains an equal number of data points.\nNatural Breaks (Jenks): Groups similar values together.\nManual: Custom classifications for specific needs.\n\nChoose a classification method that accurately represents data distribution.\nColor should enhance comprehension, not create confusion.\n\nSequential palettes for ordered data.\nDiverging palettes to show variation from a central value.\nCategorical palettes for distinct groups.\n\nEnsure colors do not overpower or obscure key map features.\nEnsure colors are harmonious\nConsider colorblind-friendly palettes\n\n\n\n13.4.4 Step 4: Layout the Map and Add Map Elements\n\nMost important features should stand out (figure-ground).\n\nBackground elements should be subtle to avoid distraction.\nContrast and transparency help differentiate primary and secondary elements.\n\nEnsure a proper zoom level. Key information should not be cut off or too close to the edge.\n\nCenter important features for focus.\nWhite space should be well distributed—avoid overcrowding.\n\nMap elements:\n\nScale Bar\n\nShould end on a logical, round number.\nUse a meaningful unit of measurement\n\nTitle\n\nShould be descriptive yet succinct.\nTypically placed at the top of the map.\nTitle frames/backgrounds are optional based on user preference.\n\nMetadata\n\nInclude essential details in a text box in the layout:\n\nAuthor’s name\nData source\nBasemap source (if used)\nCoordinate system\n\n\nFrameline\n\nMaintain space between the data frame and the page edge.\nThe data frame should be centered both horizontally and vertically.\nThe data frame should have a clear outline to improve focus.\n\nLegend\n\nMust have clear and descriptive labels (not just layer names).\nOnly include layers that are actively displayed.\nRound values appropriately (e.g., “5.23” → “5.2” or “5”).\nDo not include basemap names—mention basemap sources in Metadata instead.\n\nNorth Arrow\n\nNot always necessary. Use the following guidance:\n\nIf map is oriented north-up, a north arrow may be unnecessary.\nIf orientation differs from convention, include a north arrow.\n\n\nBasemap\n\nNot always necessary\nShould be purpose driven (adds, doesn’t detract, from map comprehension\nIllegible labels are common in QGIS basemaps.\nSolutions\n\nUse unlabeled basemaps if labels are unnecessary.\nFind a readable basemap.\nUse custom labeling tools to improve label clarity.\n\n\nText and Labeling\n\nLabels should add valuable information, not clutter.\nFollow conventional text placement (e.g., rivers labeled along their curves).\nUse rule-based labeling where needed (e.g., QuickOSM for OpenStreetMap data).\nAll text should be readable on a standard laptop screen.\nAvoid fonts that are too small or overly decorative.\n\n\n\n\n\n\n\nHarley, J B. 1989. “Deconstructing the Map.” Cartographica The International Journal for Geographic Information and Geovisualization 26 (2): 1–20. https://doi.org/10.3138/e635-7827-1757-9t53.\n\n\nWood, D. 2003. “Cartography Is Dead (Thank God!).” Cartographic Perspectives, January, 4–7. https://doi.org/10.14714/CP45.497.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Making Maps</span>"
    ]
  }
]